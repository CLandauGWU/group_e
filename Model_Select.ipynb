{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from lnks import scl_cols\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings #DANGER: I triggered a ton of warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start...\n",
    "\n",
    "We import the data output of our data pipeline. We reset the index, drop index columns, and lag the data.\n",
    "\n",
    "We explicitly print shape several times, making sure that we capture the magnitude of data lost from dropping NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shift and shape vars\n",
    "shiftmonths = 6\n",
    "shapef = 'anc'\n",
    "#Assign the split for holdout data.\n",
    "holdout_date = 2015.5\n",
    "#Get data\n",
    "filestring = './data/'+shapef+'_out.csv'\n",
    "df = pd.read_csv(filestring)\n",
    "df = df.sort_values(['month', 'NAME'])# , 'ANC'])\n",
    "df = df.reset_index(drop=True)\n",
    "len(df.NAME.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we examine the columns and lag the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'NAME', 'Util_Indx_BBL', 'countBBL', 'countIssued',\n",
       "       'month', 'TAVG', 'TMAX', 'TMIN', 'Q_GDP', 'BIZ_Dist_Concentr',\n",
       "       'GS_GRANTS_Concentr', 'LIQUOR_Concentr', 'PHARM_Concentr',\n",
       "       'GROC_Concentr', 'BANKS_Concentr', 'METRO_Concentr',\n",
       "       'pct_metro_coverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1880, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "shiftnum= (((len(df.NAME.unique()))*(shiftmonths)))\n",
    "\n",
    "#Also generate some lagged y data in the opposite direction.\n",
    "df['y']= df['countBBL'].shift(-shiftnum)\n",
    "df['countBBL_prev_month'] = df['countBBL'].shift((len(df.NAME.unique())))\n",
    "df['countBBL_prev_cycle'] = df['countBBL'].shift((shiftnum))\n",
    "df = df[shiftnum:-(shiftnum+(len(df.NAME.unique())))]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell cleans out vestigial columns and drops/fills/expands to dummies for our NA and categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1880, 59)\n",
      "(1880, 59)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['NAME'])\n",
    "df = df.drop(['Unnamed: 0'], axis= 1)\n",
    "print(df.shape)\n",
    "df = df.astype('float')\n",
    "\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start building our grid search inputs, beginning with the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Flexible adaptation of Dr. Braman's interactive gridsearch script\n",
    "#implementation. \n",
    "#TODO Clean up and streamline\n",
    "import sklearn\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "import random\n",
    "\n",
    "#Frame up some separate DataFrames for scalar and stuff\n",
    "scl_data = data = df\n",
    "\n",
    "\n",
    "\n",
    "data     = data.reset_index(drop=True)\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "XH_train = data[data['month'] <= holdout_date-1]\n",
    "yH_train = XH_train['y']\n",
    "XH_train = XH_train.drop(['y'], axis=1)\n",
    "\n",
    "XH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "XH_val = XH_val[XH_val['month'] <= holdout_date]\n",
    "\n",
    "yH_val = XH_val['y']\n",
    "XH_val = XH_val.drop(['y'], axis=1)\n",
    "\n",
    "XH_test  = data[data['month'] >= holdout_date]\n",
    "yH_test  = XH_test['y']\n",
    "XH_test  = XH_test.drop(['y'], axis=1)\n",
    "\n",
    "ytr = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "            ).fit(y)\n",
    "y = ytr.fit_transform(y)\n",
    "y = pd.DataFrame(y, columns=['y'])\n",
    "\n",
    "scl_data = scl_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.080640\n",
       "1       0.111329\n",
       "2       0.095658\n",
       "3       0.023833\n",
       "4       0.102514\n",
       "5       0.290565\n",
       "6       0.146915\n",
       "7       0.003591\n",
       "8       0.104146\n",
       "9       0.105126\n",
       "10      0.035586\n",
       "11      0.059092\n",
       "12      0.047013\n",
       "13      0.037871\n",
       "14      0.027424\n",
       "15      0.017630\n",
       "16      0.031342\n",
       "17      0.071172\n",
       "18      0.068560\n",
       "19      0.039177\n",
       "20      0.021548\n",
       "21      0.036565\n",
       "22      0.091414\n",
       "23      0.077375\n",
       "24      0.094352\n",
       "25      0.085211\n",
       "26      0.112635\n",
       "27      0.099576\n",
       "28      0.075743\n",
       "29      0.051257\n",
       "          ...   \n",
       "1850    0.174665\n",
       "1851    0.244205\n",
       "1852    0.235390\n",
       "1853    0.142018\n",
       "1854    0.133203\n",
       "1855    0.083578\n",
       "1856    0.139732\n",
       "1857    0.249102\n",
       "1858    0.233758\n",
       "1859    0.158015\n",
       "1860    0.135162\n",
       "1861    0.164871\n",
       "1862    0.339536\n",
       "1863    0.290238\n",
       "1864    0.389161\n",
       "1865    0.336272\n",
       "1866    0.457721\n",
       "1867    0.388182\n",
       "1868    0.334966\n",
       "1869    0.307542\n",
       "1870    0.183480\n",
       "1871    0.140059\n",
       "1872    0.159321\n",
       "1873    0.153771\n",
       "1874    0.113614\n",
       "1875    0.202742\n",
       "1876    0.093373\n",
       "1877    0.166177\n",
       "1878    0.108717\n",
       "1879    0.148874\n",
       "Name: y, Length: 1880, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016.05\n",
      "(1880, 59)\n",
      "(1880, 59)\n"
     ]
    }
   ],
   "source": [
    "print(scl_data.month.max())\n",
    "print(scl_data.shape)\n",
    "scl_data = scl_data.dropna()\n",
    "print(scl_data.shape)\n",
    "sXH_train = scl_data[scl_data['month'] <= holdout_date-1]\n",
    "syH_train = sXH_train['y']\n",
    "sXH_train = sXH_train.drop(['y'], axis=1)\n",
    "\n",
    "sXH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "sXH_val = sXH_val[sXH_val['month'] <= holdout_date]\n",
    "\n",
    "syH_val = sXH_val['y']\n",
    "sXH_val = sXH_val.drop(['y'], axis=1)\n",
    "\n",
    "\n",
    "sXH_test  = scl_data[scl_data['month'] >= holdout_date]\n",
    "syH_test  = sXH_test['y']\n",
    "sXH_test  = sXH_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1880, 59)\n",
      "(1880, 59)\n",
      "(1200, 58)\n",
      "(1200, 58)\n",
      "(200, 58)\n",
      "(200, 58)\n",
      "'Series' object has no attribute 'columns'\n",
      "(1200, 1)\n",
      "(1200, 1)\n",
      "'Series' object has no attribute 'columns'\n",
      "(200, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "#Build scalers for the scl_data, other --------------------\n",
    "scale_data_splits = [scl_data, sXH_train,sXH_test, syH_train, syH_test]\n",
    "for scl_data in scale_data_splits:\n",
    "    scaler = sklearn.preprocessing.StandardScaler(\n",
    "                ).fit(scl_data)\n",
    "    minmaxer = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "                ).fit(scl_data)\n",
    "\n",
    "    scl = scaler.transform(scl_data)\n",
    "    scl = minmaxer.transform(scl_data)\n",
    "    try:\n",
    "        scl_data = pd.DataFrame(scl, columns=scl_data.columns)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        scl_data = pd.DataFrame(scl, columns=['y'])\n",
    "    print(scl_data.shape)\n",
    "    scl_data = scl_data.dropna()\n",
    "    print(scl_data.shape)\n",
    "    assert np.all(np.isfinite(scl_data))\n",
    "    assert not np.any(np.isnan(scl_data))\n",
    "    \n",
    "    \n",
    "#scl_data[scl_data.columns\n",
    "#   ] = scaler.fit_transform(scl_data[scl_data.columns])\n",
    "\n",
    "#----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's make sure our data came out of the scalers intact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 58)\n",
      "(1200,)\n",
      "(200, 58)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(sXH_train.shape)\n",
    "print(syH_train.shape)\n",
    "print(sXH_test.shape)\n",
    "print(syH_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sX = scl_data.drop(['y'], axis=1)\n",
    "sy = scl_data['y']\n",
    "\n",
    "\n",
    "\n",
    "assert np.all(np.isfinite(X))\n",
    "assert np.all(np.isfinite(y))\n",
    "assert not np.any(np.isnan(X))\n",
    "assert not np.any(np.isnan(y))\n",
    "\n",
    "assert np.all(np.isfinite(sX))\n",
    "assert np.all(np.isfinite(sy))\n",
    "assert not np.any(np.isnan(sX))\n",
    "assert not np.any(np.isnan(sy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.219565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.157940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.113454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.180388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.309153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y\n",
       "count  200.000000\n",
       "mean     0.219565\n",
       "std      0.157940\n",
       "min      0.000000\n",
       "25%      0.113454\n",
       "50%      0.180388\n",
       "75%      0.309153\n",
       "max      1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains our a crude RNG, a list of regressors which benefit from scaled data, and hardcoded data used to generate our param_grid, et cetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3094, 9887, 7708, 7484, 3931, 4211, 5116, 4521, 3052, 459]\n"
     ]
    }
   ],
   "source": [
    "#Make a short list of random states to insert into randomstate params.\n",
    "scrambler = []\n",
    "for scram in range(0, 10):\n",
    "    scrambler.append(random.randint(0, 10000))   \n",
    "print(scrambler)\n",
    "\n",
    "to_scale = ['SVR']\n",
    "\n",
    "names       = ['AdaBoostRegressor',\n",
    "             'RandomForestRegressor',\n",
    "             'SVR',\n",
    "             #'KNeighborsRegressor',\n",
    "             #'BaggingRegressor',\n",
    "             'GradientBoostingRegressor',\n",
    "             #'LinearRegression',\n",
    "             #'MLPRegressor',\n",
    "             #'SGDRegressor',\n",
    "             'LassoLars'         \n",
    "    \n",
    "]\n",
    "\n",
    "regressors = [AdaBoostRegressor(),\n",
    "              RandomForestRegressor(),\n",
    "              SVR(),\n",
    "              #KNeighborsRegressor(),\n",
    "              #BaggingRegressor(),\n",
    "              GradientBoostingRegressor(),\n",
    "              #LinearRegression(),\n",
    "              #MLPRegressor(),\n",
    "              #SGDRegressor(),\n",
    "              LassoLars()\n",
    "    \n",
    "]\n",
    "\n",
    "param_grids =[ \n",
    "    ['AdaBoostRegressor', dict(\n",
    "        n_estimators=[80, 60, 30],\n",
    "        learning_rate=[1, .5, .01],\n",
    "        loss=['linear', 'square', 'exponential'],\n",
    "        #random_state=scrambler[3:5]\n",
    "        \n",
    "    )],\n",
    "        \n",
    "    ['RandomForestRegressor', dict(\n",
    "        max_depth=[5, 10, 15],\n",
    "        criterion=['mse', 'mae'],\n",
    "        #random_state=scrambler[:2]\n",
    "    )],\n",
    "    ['SVR', dict( #Most params for SVR are turned off right now, too expensive\n",
    "        C=[1, .9],\n",
    "        epsilon=[.1, .05],\n",
    "        #kernel=['poly']\n",
    "    )],\n",
    "    ['GradientBoostingRegressor', dict(\n",
    "        max_depth=[3, 6, 9, 12],\n",
    "        min_samples_split=[2, 4, 8],\n",
    "        presort=[False]\n",
    "    )],\n",
    "    ['LassoLars', dict(\n",
    "        alpha=[0.1, 1, .5, .75],\n",
    "        #random_state=[random.randint(0, 10000)]\n",
    "    )],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search:\n",
    "\n",
    "Here we implement an iterator that executes GridSearchCV and reports the best explained variance. The best_params attribute is then extracted, and used those on the whole training set, then predict on the holdout data.\n",
    "\n",
    "Testing indicates that for some models, the fit on our full dataset modestly outperforms the CV regularly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor:\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=12)]: Done  81 out of  81 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663722867574\n",
      "AdaBoostRegressor R2 with best model, score:\n",
      "0.180380746937\n",
      "RandomForestRegressor:\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  14 out of  18 | elapsed:    4.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done  18 out of  18 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653730250057\n",
      "RandomForestRegressor R2 with best model, score:\n",
      "0.211558818979\n",
      "SVR:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.8s remaining:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.464336350247\n",
      "SVR R2 with best model, score:\n",
      "-1.22957283607\n",
      "GradientBoostingRegressor:\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  36 out of  36 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638103988224\n",
      "GradientBoostingRegressor R2 with best model, score:\n",
      "0.270062226851\n",
      "LassoLars:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.4s remaining:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708104560166\n",
      "LassoLars R2 with best model, score:\n",
      "0.672667701012\n",
      "\n",
      "AdaBoostRegressor\n",
      "0.663722867574\n",
      "\n",
      "Best on real:\n",
      "0.180380746937\n",
      "\n",
      "RandomForestRegressor\n",
      "0.653730250057\n",
      "\n",
      "Best on real:\n",
      "0.211558818979\n",
      "\n",
      "SVR\n",
      "-0.464336350247\n",
      "\n",
      "Best on real:\n",
      "-1.22957283607\n",
      "\n",
      "GradientBoostingRegressor\n",
      "0.638103988224\n",
      "\n",
      "Best on real:\n",
      "0.270062226851\n",
      "\n",
      "LassoLars\n",
      "0.708104560166\n",
      "\n",
      "Best on real:\n",
      "0.672667701012\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "\n",
    "for name, rgsr in zip(names, regressors):\n",
    "    \n",
    "    for item in param_grids:\n",
    "        if item[0]==name:\n",
    "            print(name + ':')\n",
    "            params= item[1]\n",
    "        \n",
    "    \n",
    "    cv = sklearn.model_selection.GridSearchCV(rgsr, param_grid=params,\n",
    "                                              verbose=True, n_jobs=12,\n",
    "                                              cv=3, pre_dispatch=\"2*n_jobs\")\n",
    "    \n",
    "    if name not in to_scale:\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "        fitted = cv.fit(XH_train, yH_train)\n",
    "        score = cv.score(XH_val, yH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(XH_train, yH_train)\n",
    "        bestscore = best.score(XH_test, yH_test)\n",
    "    if name in to_scale:\n",
    "    #TODO: fix\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(sX, sy)\n",
    "        fitted = cv.fit(sXH_train, syH_train)\n",
    "        score = cv.score(sXH_val, syH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(sXH_train, syH_train)\n",
    "        bestscore = best.score(sXH_test, syH_test)\n",
    "\n",
    "    print(name + \" R2 with best model, score:\")\n",
    "    print(bestscore)\n",
    "    \n",
    "    \n",
    "    outcomes.append((name, score, cv.cv_results_, cv.best_estimator_, \n",
    "                     cv.best_params_, bestscore, [yH_test, ]))\n",
    "    \n",
    "for nm in range(0, len(outcomes)):\n",
    "    print()\n",
    "    print(outcomes[nm][0])\n",
    "    print(outcomes[nm][1])\n",
    "    print()\n",
    "    print('Best on real:')\n",
    "    print(outcomes[nm][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18038074693735406,\n",
       " 0.21155881897892145,\n",
       " 0,\n",
       " 0.2700622268508992,\n",
       " 0.67266770101154427]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adapted from https://pythonspot.com/en/matplotlib-bar-chart/\n",
    "\n",
    "objects     = [j[0] for j in outcomes]\n",
    "y_pos       = np.arange(len(objects))\n",
    "\n",
    "performance = [j[-1] for j in outcomes]\n",
    "for jm in range(len(performance)):\n",
    "    if performance[jm] < 0:\n",
    "        performance[jm] = 0\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEWCAYAAACdRBVEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWd/yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28fe41b9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('R2 Score')\n",
    "ti = \"Scoring across models for \"+shapef+\", lagging by \"+str(shiftmonths)+ \" months.\"\n",
    "plt.title(ti)\n",
    "fl = './plots/' + shapef + \"_shift\" + str(shiftmonths)\n",
    "plt.savefig(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below is exploratory analysis for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "0.663722867574\n",
      "{'learning_rate': 1, 'loss': 'square', 'n_estimators': 80}\n",
      "RandomForestRegressor\n",
      "0.653730250057\n",
      "{'criterion': 'mse', 'max_depth': 10}\n",
      "SVR\n",
      "-0.464336350247\n",
      "{'C': 1, 'epsilon': 0.1}\n",
      "GradientBoostingRegressor\n",
      "0.638103988224\n",
      "{'max_depth': 3, 'min_samples_split': 8, 'presort': False}\n",
      "LassoLars\n",
      "0.708104560166\n",
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "for jm in range(0, 5):\n",
    "    \n",
    "    print(outcomes[jm][0])\n",
    "    \n",
    "    print(outcomes[jm][1])\n",
    "    print(outcomes[jm][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "0.189445424722\n",
      "RandomForestRegressor\n",
      "0.274402422932\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-be6e463e4213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbestfit\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXH_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myH_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbestscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXH_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myH_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_depth'"
     ]
    }
   ],
   "source": [
    "best = AdaBoostRegressor(learning_rate=1, loss='square', n_estimators=60)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[0][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = RandomForestRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[1][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = SVR(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[2][0])\n",
    "print(bestscore)\n",
    "\n",
    "\n",
    "best = GradientBoostingRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[3][0])\n",
    "print(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xtrain = dat_xtrain.drop(['y'], axis=1)\n",
    "y16 = dat_ytrain['y']\n",
    "X15 = dat15.drop(['y'], axis=1)\n",
    "y15 = dat15['y']\n",
    "\n",
    "fitted    = outcomes[-2][3].fit(X15, y15)\n",
    "predicted = fitted.predict(X16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predicted, columns=['predicted'])\n",
    "dat16 = dat16.reset_index()\n",
    "pred['y'] = dat16['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flagger_ranges(pred):\n",
    "    pred['flag15'] = 0\n",
    "    pred['flag15'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag05'] = 0\n",
    "    pred['flag05'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag10'] = 0\n",
    "    pred['flag10'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag_others']= 0\n",
    "    pred['flag_others'][pred['flag05'] == 0] = 1\n",
    "    return pred\n",
    "pred = flagger_ranges(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
