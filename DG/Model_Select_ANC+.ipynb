{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from lnks import scl_cols\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings #DANGER: I triggered a ton of warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed()\n",
    "\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start...\n",
    "\n",
    "We import the data output of our data pipeline. We reset the index, drop index columns, and lag the data.\n",
    "\n",
    "We explicitly print shape several times, making sure that we capture the magnitude of data lost from dropping NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shift and shape vars\n",
    "shiftmonths = 6\n",
    "shapef = 'anc'\n",
    "#Assign the split for holdout data.\n",
    "holdout_date = 2015.5\n",
    "#Get data\n",
    "filestring = './data/'+shapef+'_out.csv'\n",
    "df = pd.read_csv(filestring)\n",
    "df = df.sort_values(['month', 'NAME'])# , 'ANC'])\n",
    "df = df.reset_index(drop=True)\n",
    "len(df.NAME.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we examine the columns and lag the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'NAME', 'Util_Indx_BBL', 'countBBL', 'countIssued',\n",
       "       'month', 'SALEPRICE', 'Q_GDP', 'BIZ_Dist_Concentr',\n",
       "       'GS_GRANTS_Concentr', 'LIQUOR_Concentr', 'PHARM_Concentr',\n",
       "       'GROC_Concentr', 'BANKS_Concentr', 'CLUBS_Concentr', 'HOTELS_Concentr',\n",
       "       'METRO_Concentr', 'pct_metro_coverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1806, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "shiftnum= (((len(df.NAME.unique()))*(shiftmonths)))\n",
    "\n",
    "#Also generate some lagged y data in the opposite direction.\n",
    "df['y']= df['countBBL'].shift(-shiftnum)\n",
    "df['countBBL_prev_month'] = df['countBBL'].shift((len(df.NAME.unique())))\n",
    "df['countBBL_prev_cycle'] = df['countBBL'].shift((shiftnum))\n",
    "df = df[shiftnum:-(shiftnum+(len(df.NAME.unique())))]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell cleans out vestigial columns and drops/fills/expands to dummies for our NA and categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1806, 59)\n",
      "(1806, 59)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['NAME'])\n",
    "df = df.drop(['Unnamed: 0'], axis= 1)\n",
    "print(df.shape)\n",
    "df = df.astype('float')\n",
    "\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start building our grid search inputs, beginning with the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flexible adaptation of Dr. Braman's interactive gridsearch script\n",
    "#implementation. \n",
    "#TODO Clean up and streamline\n",
    "import sklearn\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "import random\n",
    "\n",
    "#Frame up some separate DataFrames for scalar and stuff\n",
    "scl_data = data = df\n",
    "\n",
    "\n",
    "\n",
    "data     = data.reset_index(drop=True)\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "XH_train = data[data['month'] <= holdout_date-1]\n",
    "yH_train = XH_train['y']\n",
    "XH_train = XH_train.drop(['y'], axis=1)\n",
    "\n",
    "XH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "XH_val = XH_val[XH_val['month'] <= holdout_date]\n",
    "\n",
    "yH_val = XH_val['y']\n",
    "XH_val = XH_val.drop(['y'], axis=1)\n",
    "\n",
    "XH_test  = data[data['month'] >= holdout_date]\n",
    "yH_test  = XH_test['y']\n",
    "XH_test  = XH_test.drop(['y'], axis=1)\n",
    "\n",
    "ytr = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "            ).fit(y)\n",
    "y = ytr.fit_transform(y)\n",
    "y = pd.DataFrame(y, columns=['y'])\n",
    "\n",
    "scl_data = scl_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.080640\n",
       "1       0.111329\n",
       "2       0.095658\n",
       "3       0.023833\n",
       "4       0.290565\n",
       "5       0.146915\n",
       "6       0.003591\n",
       "7       0.104146\n",
       "8       0.105126\n",
       "9       0.059092\n",
       "10      0.047013\n",
       "11      0.037871\n",
       "12      0.027424\n",
       "13      0.017630\n",
       "14      0.031342\n",
       "15      0.071172\n",
       "16      0.068560\n",
       "17      0.039177\n",
       "18      0.021548\n",
       "19      0.036565\n",
       "20      0.091414\n",
       "21      0.077375\n",
       "22      0.094352\n",
       "23      0.085211\n",
       "24      0.112635\n",
       "25      0.099576\n",
       "26      0.075743\n",
       "27      0.051257\n",
       "28      0.055501\n",
       "29      0.027751\n",
       "          ...   \n",
       "1776    0.174665\n",
       "1777    0.244205\n",
       "1778    0.235390\n",
       "1779    0.142018\n",
       "1780    0.133203\n",
       "1781    0.083578\n",
       "1782    0.139732\n",
       "1783    0.249102\n",
       "1784    0.233758\n",
       "1785    0.158015\n",
       "1786    0.135162\n",
       "1787    0.164871\n",
       "1788    0.339536\n",
       "1789    0.290238\n",
       "1790    0.389161\n",
       "1791    0.336272\n",
       "1792    0.457721\n",
       "1793    0.388182\n",
       "1794    0.334966\n",
       "1795    0.307542\n",
       "1796    0.183480\n",
       "1797    0.140059\n",
       "1798    0.159321\n",
       "1799    0.153771\n",
       "1800    0.113614\n",
       "1801    0.202742\n",
       "1802    0.093373\n",
       "1803    0.166177\n",
       "1804    0.108717\n",
       "1805    0.148874\n",
       "Name: y, Length: 1806, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016.05\n",
      "(1806, 59)\n",
      "(1806, 59)\n"
     ]
    }
   ],
   "source": [
    "print(scl_data.month.max())\n",
    "print(scl_data.shape)\n",
    "scl_data = scl_data.dropna()\n",
    "print(scl_data.shape)\n",
    "sXH_train = scl_data[scl_data['month'] <= holdout_date-1]\n",
    "syH_train = sXH_train['y']\n",
    "sXH_train = sXH_train.drop(['y'], axis=1)\n",
    "\n",
    "sXH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "sXH_val = sXH_val[sXH_val['month'] <= holdout_date]\n",
    "\n",
    "syH_val = sXH_val['y']\n",
    "sXH_val = sXH_val.drop(['y'], axis=1)\n",
    "\n",
    "\n",
    "sXH_test  = scl_data[scl_data['month'] >= holdout_date]\n",
    "syH_test  = sXH_test['y']\n",
    "sXH_test  = sXH_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1806, 59)\n",
      "(1806, 59)\n",
      "(1153, 58)\n",
      "(1153, 58)\n",
      "(192, 58)\n",
      "(192, 58)\n",
      "'Series' object has no attribute 'columns'\n",
      "(1153, 1)\n",
      "(1153, 1)\n",
      "'Series' object has no attribute 'columns'\n",
      "(192, 1)\n",
      "(192, 1)\n"
     ]
    }
   ],
   "source": [
    "#Build scalers for the scl_data, other --------------------\n",
    "scale_data_splits = [scl_data, sXH_train,sXH_test, syH_train, syH_test]\n",
    "for scl_data in scale_data_splits:\n",
    "    scaler = sklearn.preprocessing.StandardScaler(\n",
    "                ).fit(scl_data)\n",
    "    minmaxer = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "                ).fit(scl_data)\n",
    "\n",
    "    scl = scaler.transform(scl_data)\n",
    "    scl = minmaxer.transform(scl_data)\n",
    "    try:\n",
    "        scl_data = pd.DataFrame(scl, columns=scl_data.columns)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        scl_data = pd.DataFrame(scl, columns=['y'])\n",
    "    print(scl_data.shape)\n",
    "    scl_data = scl_data.dropna()\n",
    "    print(scl_data.shape)\n",
    "    assert np.all(np.isfinite(scl_data))\n",
    "    assert not np.any(np.isnan(scl_data))\n",
    "    \n",
    "    \n",
    "#scl_data[scl_data.columns\n",
    "#   ] = scaler.fit_transform(scl_data[scl_data.columns])\n",
    "\n",
    "#----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's make sure our data came out of the scalers intact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1153, 58)\n",
      "(1153,)\n",
      "(192, 58)\n",
      "(192,)\n"
     ]
    }
   ],
   "source": [
    "print(sXH_train.shape)\n",
    "print(syH_train.shape)\n",
    "print(sXH_test.shape)\n",
    "print(syH_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sX = scl_data.drop(['y'], axis=1)\n",
    "sy = scl_data['y']\n",
    "\n",
    "\n",
    "\n",
    "assert np.all(np.isfinite(X))\n",
    "assert np.all(np.isfinite(y))\n",
    "assert not np.any(np.isnan(X))\n",
    "assert not np.any(np.isnan(y))\n",
    "\n",
    "assert np.all(np.isfinite(sX))\n",
    "assert np.all(np.isfinite(sy))\n",
    "assert not np.any(np.isnan(sX))\n",
    "assert not np.any(np.isnan(sy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.217014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.159491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.110775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.165156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.307066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y\n",
       "count  192.000000\n",
       "mean     0.217014\n",
       "std      0.159491\n",
       "min      0.000000\n",
       "25%      0.110775\n",
       "50%      0.165156\n",
       "75%      0.307066\n",
       "max      1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains our a crude RNG, a list of regressors which benefit from scaled data, and hardcoded data used to generate our param_grid, et cetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1808, 4760, 4545, 1472, 5015, 7827, 3079, 9442, 9846, 8522]\n"
     ]
    }
   ],
   "source": [
    "#Make a short list of random states to insert into randomstate params.\n",
    "scrambler = []\n",
    "for scram in range(0, 10):\n",
    "    scrambler.append(random.randint(0, 10000))   \n",
    "print(scrambler)\n",
    "\n",
    "to_scale = ['SVR']\n",
    "\n",
    "names       = ['AdaBoostRegressor',\n",
    "             'RandomForestRegressor',\n",
    "             'SVR',\n",
    "             #'KNeighborsRegressor',\n",
    "             #'BaggingRegressor',\n",
    "             'GradientBoostingRegressor',\n",
    "             #'LinearRegression',\n",
    "             #'MLPRegressor',\n",
    "             #'SGDRegressor',\n",
    "             'LassoLars'         \n",
    "    \n",
    "]\n",
    "\n",
    "regressors = [AdaBoostRegressor(),\n",
    "              RandomForestRegressor(),\n",
    "              SVR(),\n",
    "              #KNeighborsRegressor(),\n",
    "              #BaggingRegressor(),\n",
    "              GradientBoostingRegressor(),\n",
    "              #LinearRegression(),\n",
    "              #MLPRegressor(),\n",
    "              #SGDRegressor(),\n",
    "              LassoLars()\n",
    "    \n",
    "]\n",
    "\n",
    "param_grids =[ \n",
    "    ['AdaBoostRegressor', dict(\n",
    "        n_estimators=[80, 60, 30],\n",
    "        learning_rate=[1, .5, .01],\n",
    "        loss=['linear', 'square', 'exponential'],\n",
    "        #random_state=scrambler[3:5]\n",
    "        \n",
    "    )],\n",
    "        \n",
    "    ['RandomForestRegressor', dict(\n",
    "        max_depth=[5, 10, 15],\n",
    "        criterion=['mse', 'mae'],\n",
    "        #random_state=scrambler[:2]\n",
    "    )],\n",
    "    ['SVR', dict( #Most params for SVR are turned off right now, too expensive\n",
    "        C=[1, .9],\n",
    "        epsilon=[.1, .05],\n",
    "        #kernel=['poly']\n",
    "    )],\n",
    "    ['GradientBoostingRegressor', dict(\n",
    "        max_depth=[3, 6, 9, 12],\n",
    "        min_samples_split=[2, 4, 8],\n",
    "        presort=[False]\n",
    "    )],\n",
    "    ['LassoLars', dict(\n",
    "        alpha=[0.1, 1, .5, .75],\n",
    "        #random_state=[random.randint(0, 10000)]\n",
    "    )],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search:\n",
    "\n",
    "Here we implement an iterator that executes GridSearchCV and reports the best explained variance. The best_params attribute is then extracted, and used those on the whole training set, then predict on the holdout data.\n",
    "\n",
    "Testing indicates that for some models, the fit on our full dataset modestly outperforms the CV regularly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor:\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=12)]: Done  81 out of  81 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665054286801\n",
      "AdaBoostRegressor R2 with best model, score:\n",
      "0.162457941236\n",
      "RandomForestRegressor:\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  14 out of  18 | elapsed:    3.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done  18 out of  18 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656981418417\n",
      "RandomForestRegressor R2 with best model, score:\n",
      "0.262904394844\n",
      "SVR:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.7s remaining:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.473240311313\n",
      "SVR R2 with best model, score:\n",
      "-1.2219649632\n",
      "GradientBoostingRegressor:\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  36 out of  36 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639589177737\n",
      "GradientBoostingRegressor R2 with best model, score:\n",
      "0.270727272141\n",
      "LassoLars:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710192212102\n",
      "LassoLars R2 with best model, score:\n",
      "0.684282362284\n",
      "\n",
      "AdaBoostRegressor\n",
      "0.665054286801\n",
      "\n",
      "Best on real:\n",
      "[1614     880.0\n",
      "1615    1126.0\n",
      "1616     935.0\n",
      "1617     285.0\n",
      "1618    2597.0\n",
      "1619    1063.0\n",
      "1620    1122.0\n",
      "1621     480.0\n",
      "1622     656.0\n",
      "1623     636.0\n",
      "1624     406.0\n",
      "1625     374.0\n",
      "1626     248.0\n",
      "1627     398.0\n",
      "1628     678.0\n",
      "1629     667.0\n",
      "1630     431.0\n",
      "1631     381.0\n",
      "1632     475.0\n",
      "1633     836.0\n",
      "1634     738.0\n",
      "1635    1033.0\n",
      "1636     888.0\n",
      "1637    1197.0\n",
      "1638    1052.0\n",
      "1639     842.0\n",
      "1640     859.0\n",
      "1641     520.0\n",
      "1642     378.0\n",
      "1643     455.0\n",
      "         ...  \n",
      "1776     564.0\n",
      "1777     777.0\n",
      "1778     750.0\n",
      "1779     464.0\n",
      "1780     437.0\n",
      "1781     285.0\n",
      "1782     457.0\n",
      "1783     792.0\n",
      "1784     745.0\n",
      "1785     513.0\n",
      "1786     443.0\n",
      "1787     534.0\n",
      "1788    1069.0\n",
      "1789     918.0\n",
      "1790    1221.0\n",
      "1791    1059.0\n",
      "1792    1431.0\n",
      "1793    1218.0\n",
      "1794    1055.0\n",
      "1795     971.0\n",
      "1796     591.0\n",
      "1797     458.0\n",
      "1798     517.0\n",
      "1799     500.0\n",
      "1800     377.0\n",
      "1801     650.0\n",
      "1802     315.0\n",
      "1803     538.0\n",
      "1804     362.0\n",
      "1805     485.0\n",
      "Name: y, Length: 192, dtype: float64]\n",
      "\n",
      "RandomForestRegressor\n",
      "0.656981418417\n",
      "\n",
      "Best on real:\n",
      "[1614     880.0\n",
      "1615    1126.0\n",
      "1616     935.0\n",
      "1617     285.0\n",
      "1618    2597.0\n",
      "1619    1063.0\n",
      "1620    1122.0\n",
      "1621     480.0\n",
      "1622     656.0\n",
      "1623     636.0\n",
      "1624     406.0\n",
      "1625     374.0\n",
      "1626     248.0\n",
      "1627     398.0\n",
      "1628     678.0\n",
      "1629     667.0\n",
      "1630     431.0\n",
      "1631     381.0\n",
      "1632     475.0\n",
      "1633     836.0\n",
      "1634     738.0\n",
      "1635    1033.0\n",
      "1636     888.0\n",
      "1637    1197.0\n",
      "1638    1052.0\n",
      "1639     842.0\n",
      "1640     859.0\n",
      "1641     520.0\n",
      "1642     378.0\n",
      "1643     455.0\n",
      "         ...  \n",
      "1776     564.0\n",
      "1777     777.0\n",
      "1778     750.0\n",
      "1779     464.0\n",
      "1780     437.0\n",
      "1781     285.0\n",
      "1782     457.0\n",
      "1783     792.0\n",
      "1784     745.0\n",
      "1785     513.0\n",
      "1786     443.0\n",
      "1787     534.0\n",
      "1788    1069.0\n",
      "1789     918.0\n",
      "1790    1221.0\n",
      "1791    1059.0\n",
      "1792    1431.0\n",
      "1793    1218.0\n",
      "1794    1055.0\n",
      "1795     971.0\n",
      "1796     591.0\n",
      "1797     458.0\n",
      "1798     517.0\n",
      "1799     500.0\n",
      "1800     377.0\n",
      "1801     650.0\n",
      "1802     315.0\n",
      "1803     538.0\n",
      "1804     362.0\n",
      "1805     485.0\n",
      "Name: y, Length: 192, dtype: float64]\n",
      "\n",
      "SVR\n",
      "-0.473240311313\n",
      "\n",
      "Best on real:\n",
      "[1614     880.0\n",
      "1615    1126.0\n",
      "1616     935.0\n",
      "1617     285.0\n",
      "1618    2597.0\n",
      "1619    1063.0\n",
      "1620    1122.0\n",
      "1621     480.0\n",
      "1622     656.0\n",
      "1623     636.0\n",
      "1624     406.0\n",
      "1625     374.0\n",
      "1626     248.0\n",
      "1627     398.0\n",
      "1628     678.0\n",
      "1629     667.0\n",
      "1630     431.0\n",
      "1631     381.0\n",
      "1632     475.0\n",
      "1633     836.0\n",
      "1634     738.0\n",
      "1635    1033.0\n",
      "1636     888.0\n",
      "1637    1197.0\n",
      "1638    1052.0\n",
      "1639     842.0\n",
      "1640     859.0\n",
      "1641     520.0\n",
      "1642     378.0\n",
      "1643     455.0\n",
      "         ...  \n",
      "1776     564.0\n",
      "1777     777.0\n",
      "1778     750.0\n",
      "1779     464.0\n",
      "1780     437.0\n",
      "1781     285.0\n",
      "1782     457.0\n",
      "1783     792.0\n",
      "1784     745.0\n",
      "1785     513.0\n",
      "1786     443.0\n",
      "1787     534.0\n",
      "1788    1069.0\n",
      "1789     918.0\n",
      "1790    1221.0\n",
      "1791    1059.0\n",
      "1792    1431.0\n",
      "1793    1218.0\n",
      "1794    1055.0\n",
      "1795     971.0\n",
      "1796     591.0\n",
      "1797     458.0\n",
      "1798     517.0\n",
      "1799     500.0\n",
      "1800     377.0\n",
      "1801     650.0\n",
      "1802     315.0\n",
      "1803     538.0\n",
      "1804     362.0\n",
      "1805     485.0\n",
      "Name: y, Length: 192, dtype: float64]\n",
      "\n",
      "GradientBoostingRegressor\n",
      "0.639589177737\n",
      "\n",
      "Best on real:\n",
      "[1614     880.0\n",
      "1615    1126.0\n",
      "1616     935.0\n",
      "1617     285.0\n",
      "1618    2597.0\n",
      "1619    1063.0\n",
      "1620    1122.0\n",
      "1621     480.0\n",
      "1622     656.0\n",
      "1623     636.0\n",
      "1624     406.0\n",
      "1625     374.0\n",
      "1626     248.0\n",
      "1627     398.0\n",
      "1628     678.0\n",
      "1629     667.0\n",
      "1630     431.0\n",
      "1631     381.0\n",
      "1632     475.0\n",
      "1633     836.0\n",
      "1634     738.0\n",
      "1635    1033.0\n",
      "1636     888.0\n",
      "1637    1197.0\n",
      "1638    1052.0\n",
      "1639     842.0\n",
      "1640     859.0\n",
      "1641     520.0\n",
      "1642     378.0\n",
      "1643     455.0\n",
      "         ...  \n",
      "1776     564.0\n",
      "1777     777.0\n",
      "1778     750.0\n",
      "1779     464.0\n",
      "1780     437.0\n",
      "1781     285.0\n",
      "1782     457.0\n",
      "1783     792.0\n",
      "1784     745.0\n",
      "1785     513.0\n",
      "1786     443.0\n",
      "1787     534.0\n",
      "1788    1069.0\n",
      "1789     918.0\n",
      "1790    1221.0\n",
      "1791    1059.0\n",
      "1792    1431.0\n",
      "1793    1218.0\n",
      "1794    1055.0\n",
      "1795     971.0\n",
      "1796     591.0\n",
      "1797     458.0\n",
      "1798     517.0\n",
      "1799     500.0\n",
      "1800     377.0\n",
      "1801     650.0\n",
      "1802     315.0\n",
      "1803     538.0\n",
      "1804     362.0\n",
      "1805     485.0\n",
      "Name: y, Length: 192, dtype: float64]\n",
      "\n",
      "LassoLars\n",
      "0.710192212102\n",
      "\n",
      "Best on real:\n",
      "[1614     880.0\n",
      "1615    1126.0\n",
      "1616     935.0\n",
      "1617     285.0\n",
      "1618    2597.0\n",
      "1619    1063.0\n",
      "1620    1122.0\n",
      "1621     480.0\n",
      "1622     656.0\n",
      "1623     636.0\n",
      "1624     406.0\n",
      "1625     374.0\n",
      "1626     248.0\n",
      "1627     398.0\n",
      "1628     678.0\n",
      "1629     667.0\n",
      "1630     431.0\n",
      "1631     381.0\n",
      "1632     475.0\n",
      "1633     836.0\n",
      "1634     738.0\n",
      "1635    1033.0\n",
      "1636     888.0\n",
      "1637    1197.0\n",
      "1638    1052.0\n",
      "1639     842.0\n",
      "1640     859.0\n",
      "1641     520.0\n",
      "1642     378.0\n",
      "1643     455.0\n",
      "         ...  \n",
      "1776     564.0\n",
      "1777     777.0\n",
      "1778     750.0\n",
      "1779     464.0\n",
      "1780     437.0\n",
      "1781     285.0\n",
      "1782     457.0\n",
      "1783     792.0\n",
      "1784     745.0\n",
      "1785     513.0\n",
      "1786     443.0\n",
      "1787     534.0\n",
      "1788    1069.0\n",
      "1789     918.0\n",
      "1790    1221.0\n",
      "1791    1059.0\n",
      "1792    1431.0\n",
      "1793    1218.0\n",
      "1794    1055.0\n",
      "1795     971.0\n",
      "1796     591.0\n",
      "1797     458.0\n",
      "1798     517.0\n",
      "1799     500.0\n",
      "1800     377.0\n",
      "1801     650.0\n",
      "1802     315.0\n",
      "1803     538.0\n",
      "1804     362.0\n",
      "1805     485.0\n",
      "Name: y, Length: 192, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "\n",
    "for name, rgsr in zip(names, regressors):\n",
    "    \n",
    "    for item in param_grids:\n",
    "        if item[0]==name:\n",
    "            print(name + ':')\n",
    "            params= item[1]\n",
    "        \n",
    "    \n",
    "    cv = sklearn.model_selection.GridSearchCV(rgsr, param_grid=params,\n",
    "                                              verbose=True, n_jobs=12,\n",
    "                                              cv=3, pre_dispatch=\"2*n_jobs\")\n",
    "    \n",
    "    if name not in to_scale:\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "        fitted = cv.fit(XH_train, yH_train)\n",
    "        score = cv.score(XH_val, yH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(XH_train, yH_train)\n",
    "        bestscore = best.score(XH_test, yH_test)\n",
    "    if name in to_scale:\n",
    "    #TODO: fix\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(sX, sy)\n",
    "        fitted = cv.fit(sXH_train, syH_train)\n",
    "        score = cv.score(sXH_val, syH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(sXH_train, syH_train)\n",
    "        bestscore = best.score(sXH_test, syH_test)\n",
    "\n",
    "    print(name + \" R2 with best model, score:\")\n",
    "    print(bestscore)\n",
    "    \n",
    "    outcomes.append((name, score, cv.cv_results_, cv.best_estimator_, \n",
    "                     cv.best_params_, bestscore, [yH_test, ]))\n",
    "    \n",
    "for nm in range(0, len(outcomes)):\n",
    "    print()\n",
    "    print(outcomes[nm][0])\n",
    "    print(outcomes[nm][1])\n",
    "\n",
    "    print()\n",
    "    print('Best on real:')\n",
    "    print(outcomes[nm][-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis - ANC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_ANC 2D           -0.157043\n",
       "NAME_ANC 3G           -0.127025\n",
       "NAME_ANC 8B           -0.120614\n",
       "NAME_ANC 1D           -0.111773\n",
       "NAME_ANC 8D           -0.110460\n",
       "NAME_ANC 8E           -0.110459\n",
       "NAME_ANC 7F           -0.107834\n",
       "NAME_ANC 5A           -0.103933\n",
       "Q_GDP                 -0.094681\n",
       "NAME_ANC 7E           -0.093497\n",
       "NAME_ANC 7C           -0.092511\n",
       "NAME_ANC 3F           -0.087482\n",
       "NAME_ANC 4A           -0.083163\n",
       "NAME_ANC 3B           -0.067292\n",
       "NAME_ANC 8C           -0.066835\n",
       "NAME_ANC 4D           -0.066473\n",
       "NAME_ANC 5B           -0.065804\n",
       "NAME_ANC 3E           -0.062881\n",
       "NAME_ANC 7D           -0.054043\n",
       "NAME_ANC 7B           -0.053850\n",
       "NAME_ANC 3D           -0.034633\n",
       "NAME_ANC 8A           -0.029727\n",
       "NAME_ANC 3C           -0.021149\n",
       "NAME_ANC 4B           -0.001649\n",
       "NAME_ANC 4C            0.004583\n",
       "NAME_ANC 6E            0.012039\n",
       "NAME_ANC 5D            0.035697\n",
       "NAME_ANC 6D            0.036477\n",
       "NAME_ANC 5C            0.057430\n",
       "NAME_ANC 6A            0.060772\n",
       "NAME_ANC 1C            0.069525\n",
       "NAME_ANC 1A            0.071650\n",
       "NAME_ANC 2A            0.076045\n",
       "NAME_ANC 6C            0.098470\n",
       "SALEPRICE              0.101700\n",
       "NAME_ANC 2C            0.103577\n",
       "NAME_ANC 2E            0.106039\n",
       "NAME_ANC 5E            0.112951\n",
       "NAME_ANC 1B            0.135624\n",
       "NAME_ANC 2F            0.141437\n",
       "NAME_ANC 6B            0.143918\n",
       "GS_GRANTS_Concentr     0.155415\n",
       "month                  0.430127\n",
       "BIZ_Dist_Concentr      0.475610\n",
       "pct_metro_coverage     0.490740\n",
       "METRO_Concentr         0.541070\n",
       "LIQUOR_Concentr        0.541070\n",
       "PHARM_Concentr         0.541070\n",
       "GROC_Concentr          0.541070\n",
       "BANKS_Concentr         0.541070\n",
       "CLUBS_Concentr         0.541070\n",
       "HOTELS_Concentr        0.541070\n",
       "NAME_ANC 2B            0.578353\n",
       "Util_Indx_BBL          0.766211\n",
       "countIssued            0.777290\n",
       "countBBL_prev_cycle    0.880682\n",
       "countBBL_prev_month    0.942853\n",
       "countBBL               0.957302\n",
       "y                      1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLars\n",
      "LassoLars(alpha=0.1, copy_X=True, eps=2.2204460492503131e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
      "     positive=False, precompute='auto', verbose=False)\n",
      "\n",
      "Score on test data:\n",
      "0.684282362284\n",
      "\n",
      "[[    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.          6216.72201882  6256.80861373  6265.69767498\n",
      "   6271.48797788  6269.59571783  6257.96561371  6235.46600107\n",
      "   6139.04689839  6058.37030459]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.            -8.44824813\n",
      "    -39.33430977   -79.52376821   -85.33632522  -100.16624932\n",
      "   -106.70627799]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.\n",
      "     23.64071733    51.71412322    55.6578862     67.07700782\n",
      "     76.57075994]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.            14.31195131]\n",
      " [    0.             0.            40.08659491    87.40306334\n",
      "     90.00313334   110.62961088   140.74047323   144.98130574\n",
      "    165.11672709   178.87287491]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "     15.74163878    17.94958536    26.17997004    34.61103723]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.            20.98319726    98.51375768   153.80668685]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.            46.52023427\n",
      "     48.66281692    66.11494277    90.45481573    93.83227659   111.111194\n",
      "    130.72644085]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.            19.79877408    32.28975968]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]\n",
      " [    0.             0.             0.             0.             0.             0.\n",
      "      0.             0.             0.             0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#LassoLARS\n",
    "blist = outcomes[-1] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = LassoLars(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.coef_path_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month', -4.2591021139608349),\n",
       " ('Util_Indx_BBL', 0.0),\n",
       " ('countIssued', 0.0),\n",
       " ('SALEPRICE', 0.0),\n",
       " ('Q_GDP', 0.0),\n",
       " ('PHARM_Concentr', 0.0),\n",
       " ('GROC_Concentr', 0.0),\n",
       " ('BANKS_Concentr', 0.0),\n",
       " ('CLUBS_Concentr', 0.0),\n",
       " ('HOTELS_Concentr', 0.0),\n",
       " ('METRO_Concentr', 0.0),\n",
       " ('countBBL_prev_cycle', 0.0),\n",
       " ('NAME_ANC 1A', 0.0),\n",
       " ('NAME_ANC 1B', 0.0),\n",
       " ('NAME_ANC 1C', 0.0),\n",
       " ('NAME_ANC 1D', 0.0),\n",
       " ('NAME_ANC 2A', 0.0),\n",
       " ('NAME_ANC 2C', 0.0),\n",
       " ('NAME_ANC 2D', 0.0),\n",
       " ('NAME_ANC 2E', 0.0),\n",
       " ('NAME_ANC 3B', 0.0),\n",
       " ('NAME_ANC 3C', 0.0),\n",
       " ('NAME_ANC 3D', 0.0),\n",
       " ('NAME_ANC 3E', 0.0),\n",
       " ('NAME_ANC 3F', 0.0),\n",
       " ('NAME_ANC 3G', 0.0),\n",
       " ('NAME_ANC 4A', 0.0),\n",
       " ('NAME_ANC 4B', 0.0),\n",
       " ('NAME_ANC 4C', 0.0),\n",
       " ('NAME_ANC 4D', 0.0),\n",
       " ('NAME_ANC 5A', 0.0),\n",
       " ('NAME_ANC 5B', 0.0),\n",
       " ('NAME_ANC 5C', 0.0),\n",
       " ('NAME_ANC 5D', 0.0),\n",
       " ('NAME_ANC 5E', 0.0),\n",
       " ('NAME_ANC 6A', 0.0),\n",
       " ('NAME_ANC 6B', 0.0),\n",
       " ('NAME_ANC 6C', 0.0),\n",
       " ('NAME_ANC 6D', 0.0),\n",
       " ('NAME_ANC 6E', 0.0),\n",
       " ('NAME_ANC 7B', 0.0),\n",
       " ('NAME_ANC 7C', 0.0),\n",
       " ('NAME_ANC 7D', 0.0),\n",
       " ('NAME_ANC 7E', 0.0),\n",
       " ('NAME_ANC 7F', 0.0),\n",
       " ('NAME_ANC 8A', 0.0),\n",
       " ('NAME_ANC 8B', 0.0),\n",
       " ('NAME_ANC 8C', 0.0),\n",
       " ('NAME_ANC 8D', 0.0),\n",
       " ('NAME_ANC 8E', 0.0),\n",
       " ('LIQUOR_Concentr', 0.0030480698990927929),\n",
       " ('countBBL_prev_month', 0.024834754226241575),\n",
       " ('countBBL', 0.96661136808181158),\n",
       " ('GS_GRANTS_Concentr', 1.1314831621487951),\n",
       " ('pct_metro_coverage', 5.0076087203688902),\n",
       " ('BIZ_Dist_Concentr', 6.0734372886098607),\n",
       " ('NAME_ANC 2F', 6.2882295779723467),\n",
       " ('NAME_ANC 2B', 24.183969442800922)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lars_anc_beta = [i for i in zip(XH_test.columns, prms.coef_)]\n",
    "sorted(lars_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "         n_estimators=80, random_state=None)\n",
      "\n",
      "Score on test data:\n",
      "0.175647234336\n",
      "\n",
      "[  1.81794620e-03   2.93414370e-01   4.09508032e-04   5.32752129e-03\n",
      "   1.49346362e-03   2.50407895e-04   2.51404405e-03   1.27202622e-03\n",
      "   5.22126972e-02   4.20296912e-02   3.48410873e-02   2.80261711e-02\n",
      "   2.93298365e-02   4.15368900e-02   4.18834652e-02   5.59328168e-03\n",
      "   2.20146763e-01   1.49228190e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.92691286e-02\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   9.40351091e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "blist = outcomes[0] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = AdaBoostRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NAME_ANC 1A', 0.0),\n",
       " ('NAME_ANC 1B', 0.0),\n",
       " ('NAME_ANC 1C', 0.0),\n",
       " ('NAME_ANC 1D', 0.0),\n",
       " ('NAME_ANC 2A', 0.0),\n",
       " ('NAME_ANC 2C', 0.0),\n",
       " ('NAME_ANC 2D', 0.0),\n",
       " ('NAME_ANC 2E', 0.0),\n",
       " ('NAME_ANC 3B', 0.0),\n",
       " ('NAME_ANC 3C', 0.0),\n",
       " ('NAME_ANC 3D', 0.0),\n",
       " ('NAME_ANC 3E', 0.0),\n",
       " ('NAME_ANC 3F', 0.0),\n",
       " ('NAME_ANC 3G', 0.0),\n",
       " ('NAME_ANC 4A', 0.0),\n",
       " ('NAME_ANC 4B', 0.0),\n",
       " ('NAME_ANC 4C', 0.0),\n",
       " ('NAME_ANC 4D', 0.0),\n",
       " ('NAME_ANC 5A', 0.0),\n",
       " ('NAME_ANC 5B', 0.0),\n",
       " ('NAME_ANC 5C', 0.0),\n",
       " ('NAME_ANC 5D', 0.0),\n",
       " ('NAME_ANC 5E', 0.0),\n",
       " ('NAME_ANC 6A', 0.0),\n",
       " ('NAME_ANC 6B', 0.0),\n",
       " ('NAME_ANC 6C', 0.0),\n",
       " ('NAME_ANC 6D', 0.0),\n",
       " ('NAME_ANC 6E', 0.0),\n",
       " ('NAME_ANC 7B', 0.0),\n",
       " ('NAME_ANC 7C', 0.0),\n",
       " ('NAME_ANC 7D', 0.0),\n",
       " ('NAME_ANC 7E', 0.0),\n",
       " ('NAME_ANC 7F', 0.0),\n",
       " ('NAME_ANC 8A', 0.0),\n",
       " ('NAME_ANC 8B', 0.0),\n",
       " ('NAME_ANC 8C', 0.0),\n",
       " ('NAME_ANC 8D', 0.0),\n",
       " ('NAME_ANC 8E', 0.0),\n",
       " ('Q_GDP', 0.00025040789524748798),\n",
       " ('countIssued', 0.00040950803197946893),\n",
       " ('GS_GRANTS_Concentr', 0.0012720262171296783),\n",
       " ('SALEPRICE', 0.001493463621384849),\n",
       " ('Util_Indx_BBL', 0.001817946199962723),\n",
       " ('BIZ_Dist_Concentr', 0.0025140440529970104),\n",
       " ('month', 0.0053275212887323323),\n",
       " ('pct_metro_coverage', 0.0055932816820275051),\n",
       " ('NAME_ANC 2F', 0.0094035109111676174),\n",
       " ('BANKS_Concentr', 0.028026171059729314),\n",
       " ('CLUBS_Concentr', 0.029329836477913623),\n",
       " ('GROC_Concentr', 0.034841087297812878),\n",
       " ('NAME_ANC 2B', 0.039269128635359626),\n",
       " ('HOTELS_Concentr', 0.0415368900112041),\n",
       " ('METRO_Concentr', 0.041883465192833445),\n",
       " ('PHARM_Concentr', 0.042029691207756341),\n",
       " ('LIQUOR_Concentr', 0.052212697248767849),\n",
       " ('countBBL_prev_cycle', 0.14922819010572272),\n",
       " ('countBBL_prev_month', 0.22014676329346056),\n",
       " ('countBBL', 0.29341436956881084)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(ada_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "Score on test data:\n",
      "0.251312055252\n",
      "\n",
      "[  2.02283447e-03   6.60635315e-01   3.19863454e-04   3.11861042e-03\n",
      "   5.45470030e-04   2.48135117e-04   8.39666823e-04   4.87389525e-04\n",
      "   5.38760575e-02   5.65097495e-05   5.56233443e-02   2.47953378e-02\n",
      "   3.18914424e-04   2.36092051e-04   3.24489015e-02   7.52398985e-04\n",
      "   9.90851257e-02   3.22376369e-02   1.12362002e-05   1.53055984e-05\n",
      "   2.88424908e-04   1.12635579e-06   8.19950879e-08   3.09755644e-02\n",
      "   0.00000000e+00   1.40389122e-04   4.23306699e-07   3.20073998e-04\n",
      "   4.85376039e-06   2.01018010e-06   5.02048269e-06   3.65741931e-06\n",
      "   7.48038225e-06   1.91383144e-05   4.27477850e-06   7.74457357e-06\n",
      "   4.70935781e-07   9.54957003e-06   3.04232815e-06   3.87156586e-06\n",
      "   4.90796142e-06   3.23046483e-07   5.94044116e-06   6.43492415e-05\n",
      "   2.28344850e-06   4.65884405e-05   1.44633707e-04   2.54103803e-05\n",
      "   8.33350992e-05   1.57751188e-05   9.03512732e-06   2.94309403e-06\n",
      "   3.65198169e-06   2.59241433e-06   1.08401955e-07   8.62324617e-05\n",
      "   9.82398165e-06   2.07221776e-05]\n"
     ]
    }
   ],
   "source": [
    "#RFR \n",
    "blist = outcomes[1] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = RandomForestRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NAME_ANC 2C', 0.0),\n",
       " ('NAME_ANC 2A', 8.1995087905884305e-08),\n",
       " ('NAME_ANC 8B', 1.0840195467495942e-07),\n",
       " ('NAME_ANC 5D', 3.2304648317395513e-07),\n",
       " ('NAME_ANC 2E', 4.2330669915968555e-07),\n",
       " ('NAME_ANC 4C', 4.7093578091800742e-07),\n",
       " ('NAME_ANC 1D', 1.1263557943792851e-06),\n",
       " ('NAME_ANC 3C', 2.0101800963179686e-06),\n",
       " ('NAME_ANC 6B', 2.2834485010441945e-06),\n",
       " ('NAME_ANC 8A', 2.5924143289289887e-06),\n",
       " ('NAME_ANC 7E', 2.9430940330511685e-06),\n",
       " ('NAME_ANC 5A', 3.042328149762627e-06),\n",
       " ('NAME_ANC 7F', 3.6519816892099328e-06),\n",
       " ('NAME_ANC 3E', 3.6574193115077753e-06),\n",
       " ('NAME_ANC 5B', 3.8715658589832485e-06),\n",
       " ('NAME_ANC 4A', 4.2747785048551197e-06),\n",
       " ('NAME_ANC 3B', 4.8537603859206763e-06),\n",
       " ('NAME_ANC 5C', 4.9079614203675476e-06),\n",
       " ('NAME_ANC 3D', 5.0204826874746332e-06),\n",
       " ('NAME_ANC 5E', 5.9404411587467802e-06),\n",
       " ('NAME_ANC 3F', 7.4803822549498193e-06),\n",
       " ('NAME_ANC 4B', 7.7445735664377928e-06),\n",
       " ('NAME_ANC 7D', 9.035127318528327e-06),\n",
       " ('NAME_ANC 4D', 9.5495700314294917e-06),\n",
       " ('NAME_ANC 8D', 9.8239816474509827e-06),\n",
       " ('NAME_ANC 1A', 1.1236200167006019e-05),\n",
       " ('NAME_ANC 1B', 1.5305598418283564e-05),\n",
       " ('NAME_ANC 7C', 1.5775118829120423e-05),\n",
       " ('NAME_ANC 3G', 1.9138314381973266e-05),\n",
       " ('NAME_ANC 8E', 2.0722177583947682e-05),\n",
       " ('NAME_ANC 6E', 2.5410380325544884e-05),\n",
       " ('NAME_ANC 6C', 4.6588440545397324e-05),\n",
       " ('PHARM_Concentr', 5.6509749490460177e-05),\n",
       " ('NAME_ANC 6A', 6.4349241464295529e-05),\n",
       " ('NAME_ANC 7B', 8.333509920735052e-05),\n",
       " ('NAME_ANC 8C', 8.6232461659737508e-05),\n",
       " ('NAME_ANC 2D', 0.00014038912204283223),\n",
       " ('NAME_ANC 6D', 0.00014463370661220467),\n",
       " ('HOTELS_Concentr', 0.00023609205089268197),\n",
       " ('Q_GDP', 0.0002481351174955012),\n",
       " ('NAME_ANC 1C', 0.00028842490787945598),\n",
       " ('CLUBS_Concentr', 0.00031891442367666819),\n",
       " ('countIssued', 0.00031986345414872924),\n",
       " ('NAME_ANC 2F', 0.00032007399770972363),\n",
       " ('GS_GRANTS_Concentr', 0.00048738952462182034),\n",
       " ('SALEPRICE', 0.00054547002973371283),\n",
       " ('pct_metro_coverage', 0.00075239898531007218),\n",
       " ('BIZ_Dist_Concentr', 0.00083966682278491505),\n",
       " ('Util_Indx_BBL', 0.002022834466652221),\n",
       " ('month', 0.0031186104195821168),\n",
       " ('BANKS_Concentr', 0.024795337810607072),\n",
       " ('NAME_ANC 2B', 0.030975564372752395),\n",
       " ('countBBL_prev_cycle', 0.03223763685277499),\n",
       " ('METRO_Concentr', 0.032448901456994403),\n",
       " ('LIQUOR_Concentr', 0.053876057483580694),\n",
       " ('GROC_Concentr', 0.055623344267761068),\n",
       " ('countBBL_prev_month', 0.099085125654902489),\n",
       " ('countBBL', 0.66063531475666593)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(rfr_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=8,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100, presort=False,\n",
      "             random_state=None, subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "Score on test data:\n",
      "0.276460308395\n",
      "\n",
      "[ 0.06554758  0.17594069  0.01762628  0.16832463  0.02560154  0.03097537\n",
      "  0.01940928  0.02778066  0.00151913  0.00926952  0.00829651  0.0082839\n",
      "  0.01168314  0.00438671  0.00679253  0.04777374  0.10553871  0.13935976\n",
      "  0.          0.          0.          0.          0.          0.00518118\n",
      "  0.          0.00081705  0.01667949  0.01750668  0.00030081  0.00071238\n",
      "  0.01018708  0.00586049  0.          0.00183213  0.00232989  0.\n",
      "  0.00595856  0.          0.          0.          0.00129933  0.\n",
      "  0.00922482  0.          0.00156557  0.00171152  0.00657107  0.01706904\n",
      "  0.00743576  0.          0.          0.          0.          0.          0.\n",
      "  0.01308967  0.          0.00055778]\n"
     ]
    }
   ],
   "source": [
    "#GBR  \n",
    "blist = outcomes[3] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = GradientBoostingRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NAME_ANC 1A', 0.0),\n",
       " ('NAME_ANC 1B', 0.0),\n",
       " ('NAME_ANC 1C', 0.0),\n",
       " ('NAME_ANC 1D', 0.0),\n",
       " ('NAME_ANC 2A', 0.0),\n",
       " ('NAME_ANC 2C', 0.0),\n",
       " ('NAME_ANC 3F', 0.0),\n",
       " ('NAME_ANC 4B', 0.0),\n",
       " ('NAME_ANC 4D', 0.0),\n",
       " ('NAME_ANC 5A', 0.0),\n",
       " ('NAME_ANC 5B', 0.0),\n",
       " ('NAME_ANC 5D', 0.0),\n",
       " ('NAME_ANC 6A', 0.0),\n",
       " ('NAME_ANC 7C', 0.0),\n",
       " ('NAME_ANC 7D', 0.0),\n",
       " ('NAME_ANC 7E', 0.0),\n",
       " ('NAME_ANC 7F', 0.0),\n",
       " ('NAME_ANC 8A', 0.0),\n",
       " ('NAME_ANC 8B', 0.0),\n",
       " ('NAME_ANC 8D', 0.0),\n",
       " ('NAME_ANC 3B', 0.00030081177003266481),\n",
       " ('NAME_ANC 8E', 0.00055777523938999171),\n",
       " ('NAME_ANC 3C', 0.00071237899636898293),\n",
       " ('NAME_ANC 2D', 0.00081705238811436982),\n",
       " ('NAME_ANC 5C', 0.0012993277478813947),\n",
       " ('LIQUOR_Concentr', 0.0015191344268845513),\n",
       " ('NAME_ANC 6B', 0.0015655727960165915),\n",
       " ('NAME_ANC 6C', 0.00171151931160489),\n",
       " ('NAME_ANC 3G', 0.0018321263033114765),\n",
       " ('NAME_ANC 4A', 0.0023298923169682833),\n",
       " ('HOTELS_Concentr', 0.0043867072209121992),\n",
       " ('NAME_ANC 2B', 0.0051811786860568665),\n",
       " ('NAME_ANC 3E', 0.0058604935313703085),\n",
       " ('NAME_ANC 4C', 0.0059585598348731728),\n",
       " ('NAME_ANC 6D', 0.0065710661992227394),\n",
       " ('METRO_Concentr', 0.0067925331008642656),\n",
       " ('NAME_ANC 7B', 0.0074357622196525438),\n",
       " ('BANKS_Concentr', 0.0082838979177861146),\n",
       " ('GROC_Concentr', 0.0082965148866533996),\n",
       " ('NAME_ANC 5E', 0.009224822357909777),\n",
       " ('PHARM_Concentr', 0.0092695197763983245),\n",
       " ('NAME_ANC 3D', 0.010187079818295579),\n",
       " ('CLUBS_Concentr', 0.011683135172879474),\n",
       " ('NAME_ANC 8C', 0.013089671942361573),\n",
       " ('NAME_ANC 2E', 0.016679494259286613),\n",
       " ('NAME_ANC 6E', 0.017069038401118144),\n",
       " ('NAME_ANC 2F', 0.017506682253610448),\n",
       " ('countIssued', 0.017626283907330335),\n",
       " ('BIZ_Dist_Concentr', 0.019409283192521311),\n",
       " ('SALEPRICE', 0.02560154326423408),\n",
       " ('GS_GRANTS_Concentr', 0.027780661184604462),\n",
       " ('Q_GDP', 0.030975370547714768),\n",
       " ('pct_metro_coverage', 0.047773744079714534),\n",
       " ('Util_Indx_BBL', 0.065547578756555466),\n",
       " ('countBBL_prev_month', 0.10553870934980888),\n",
       " ('countBBL_prev_cycle', 0.13935975848736279),\n",
       " ('month', 0.16832462884788865),\n",
       " ('countBBL', 0.17594068950644004)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(gbr_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from https://pythonspot.com/en/matplotlib-bar-chart/\n",
    "\n",
    "objects     = [j[0] for j in outcomes]\n",
    "y_pos       = np.arange(len(objects))\n",
    "\n",
    "performance = [j[-1] for j in outcomes]\n",
    "for jm in range(len(performance)):\n",
    "    if performance[jm] < 0:\n",
    "        performance[jm] = 0\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('R2 Score')\n",
    "ti = \"Scoring across models for \"+shapef+\", lagging by \"+str(shiftmonths)+ \" months.\"\n",
    "plt.title(ti)\n",
    "fl = './plots/' + shapef + \"_shift\" + str(shiftmonths)\n",
    "plt.savefig(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below is exploratory analysis for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for jm in range(0, 5):\n",
    "    \n",
    "    print(outcomes[jm][0])\n",
    "    \n",
    "    print(outcomes[jm][1])\n",
    "    print(outcomes[jm][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = AdaBoostRegressor(learning_rate=1, loss='square', n_estimators=60)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[0][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = RandomForestRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[1][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = SVR(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[2][0])\n",
    "print(bestscore)\n",
    "\n",
    "\n",
    "best = GradientBoostingRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[3][0])\n",
    "print(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xtrain = dat_xtrain.drop(['y'], axis=1)\n",
    "y16 = dat_ytrain['y']\n",
    "X15 = dat15.drop(['y'], axis=1)\n",
    "y15 = dat15['y']\n",
    "\n",
    "fitted    = outcomes[-2][3].fit(X15, y15)\n",
    "predicted = fitted.predict(X16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predicted, columns=['predicted'])\n",
    "dat16 = dat16.reset_index()\n",
    "pred['y'] = dat16['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flagger_ranges(pred):\n",
    "    pred['flag15'] = 0\n",
    "    pred['flag15'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag05'] = 0\n",
    "    pred['flag05'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag10'] = 0\n",
    "    pred['flag10'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag_others']= 0\n",
    "    pred['flag_others'][pred['flag05'] == 0] = 1\n",
    "    return pred\n",
    "pred = flagger_ranges(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
