{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from lnks import scl_cols\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings #DANGER: I triggered a ton of warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed()\n",
    "\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start...\n",
    "\n",
    "We import the data output of our data pipeline. We reset the index, drop index columns, and lag the data.\n",
    "\n",
    "We explicitly print shape several times, making sure that we capture the magnitude of data lost from dropping NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shift and shape vars\n",
    "shiftmonths = 6\n",
    "shapef = 'ward'\n",
    "#Assign the split for holdout data.\n",
    "holdout_date = 2015.5\n",
    "#Get data\n",
    "filestring = './data/'+shapef+'_out.csv'\n",
    "df = pd.read_csv(filestring)\n",
    "df = df.sort_values(['month', 'NAME'])# , 'ANC'])\n",
    "df = df.reset_index(drop=True)\n",
    "len(df.NAME.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we examine the columns and lag the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'NAME', 'Util_Indx_BBL', 'countBBL', 'countIssued',\n",
       "       'month', 'SALEPRICE', 'Q_GDP', 'BIZ_Dist_Concentr',\n",
       "       'GS_GRANTS_Concentr', 'LIQUOR_Concentr', 'PHARM_Concentr',\n",
       "       'GROC_Concentr', 'BANKS_Concentr', 'CLUBS_Concentr', 'HOTELS_Concentr',\n",
       "       'METRO_Concentr', 'pct_metro_coverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Util_Indx_BBL</th>\n",
       "      <th>countBBL</th>\n",
       "      <th>countIssued</th>\n",
       "      <th>month</th>\n",
       "      <th>SALEPRICE</th>\n",
       "      <th>Q_GDP</th>\n",
       "      <th>BIZ_Dist_Concentr</th>\n",
       "      <th>GS_GRANTS_Concentr</th>\n",
       "      <th>LIQUOR_Concentr</th>\n",
       "      <th>PHARM_Concentr</th>\n",
       "      <th>GROC_Concentr</th>\n",
       "      <th>BANKS_Concentr</th>\n",
       "      <th>CLUBS_Concentr</th>\n",
       "      <th>HOTELS_Concentr</th>\n",
       "      <th>METRO_Concentr</th>\n",
       "      <th>pct_metro_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>ANC 1A</td>\n",
       "      <td>0.038227</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.049174</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>0.307071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>ANC 1B</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>267.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012.01</td>\n",
       "      <td>727000.0</td>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.979311</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>5875</td>\n",
       "      <td>0.436447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ANC 1C</td>\n",
       "      <td>0.054142</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012.01</td>\n",
       "      <td>1986000.0</td>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.998646</td>\n",
       "      <td>0.927854</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>3694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ANC 1D</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012.01</td>\n",
       "      <td>783000.0</td>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.264922</td>\n",
       "      <td>0.692668</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>2178</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ANC 2A</td>\n",
       "      <td>0.068413</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012.01</td>\n",
       "      <td>158000000.0</td>\n",
       "      <td>0.663452</td>\n",
       "      <td>0.800974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>3435</td>\n",
       "      <td>0.414556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    NAME  Util_Indx_BBL  countBBL  countIssued    month  \\\n",
       "0          17  ANC 1A       0.038227     213.0          1.0  2012.01   \n",
       "1          18  ANC 1B       0.045447     267.0          4.0  2012.01   \n",
       "2           0  ANC 1C       0.054142     200.0          1.0  2012.01   \n",
       "3           1  ANC 1D       0.030303      66.0          0.0  2012.01   \n",
       "4           2  ANC 2A       0.068413     235.0          3.0  2012.01   \n",
       "\n",
       "     SALEPRICE     Q_GDP  BIZ_Dist_Concentr  GS_GRANTS_Concentr  \\\n",
       "0          NaN  0.663452           0.049174            0.981043   \n",
       "1     727000.0  0.663452           0.029787            0.979311   \n",
       "2    1986000.0  0.663452           0.998646            0.927854   \n",
       "3     783000.0  0.663452           0.264922            0.692668   \n",
       "4  158000000.0  0.663452           0.800974            0.000000   \n",
       "\n",
       "   LIQUOR_Concentr  PHARM_Concentr  GROC_Concentr  BANKS_Concentr  \\\n",
       "0             5572            5572           5572            5572   \n",
       "1             5875            5875           5875            5875   \n",
       "2             3694            3694           3694            3694   \n",
       "3             2178            2178           2178            2178   \n",
       "4             3435            3435           3435            3435   \n",
       "\n",
       "   CLUBS_Concentr  HOTELS_Concentr  METRO_Concentr  pct_metro_coverage  \n",
       "0            5572             5572            5572            0.307071  \n",
       "1            5875             5875            5875            0.436447  \n",
       "2            3694             3694            3694            0.000000  \n",
       "3            2178             2178            2178            0.000000  \n",
       "4            3435             3435            3435            0.414556  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2182, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "shiftnum= (((len(df.NAME.unique()))*(shiftmonths)))\n",
    "\n",
    "#Also generate some lagged y data in the opposite direction.\n",
    "df['y']= df['countBBL'].shift(-shiftnum)\n",
    "df['countBBL_prev_month'] = df['countBBL'].shift((len(df.NAME.unique())))\n",
    "df['countBBL_prev_cycle'] = df['countBBL'].shift((shiftnum))\n",
    "df = df[shiftnum:-(shiftnum+(len(df.NAME.unique())))]\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell cleans out vestigial columns and drops/fills/expands to dummies for our NA and categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('NAME', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Util_Indx_BBL', 'countBBL', 'countIssued', 'month',\n",
       "       'SALEPRICE', 'Q_GDP', 'BIZ_Dist_Concentr', 'GS_GRANTS_Concentr',\n",
       "       'LIQUOR_Concentr', 'PHARM_Concentr', 'GROC_Concentr', 'BANKS_Concentr',\n",
       "       'CLUBS_Concentr', 'HOTELS_Concentr', 'METRO_Concentr',\n",
       "       'pct_metro_coverage', 'y', 'countBBL_prev_month',\n",
       "       'countBBL_prev_cycle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start building our grid search inputs, beginning with the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Flexible adaptation of Dr. Braman's interactive gridsearch script\n",
    "#implementation. \n",
    "#TODO Clean up and streamline\n",
    "import sklearn\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.gaussian_process import *\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "import random\n",
    "\n",
    "#Frame up some separate DataFrames for scalar and stuff\n",
    "scl_data = data = df\n",
    "\n",
    "\n",
    "\n",
    "data     = data.reset_index(drop=True)\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "XH_train = data[data['month'] <= holdout_date-1]\n",
    "yH_train = XH_train['y']\n",
    "XH_train = XH_train.drop(['y'], axis=1)\n",
    "\n",
    "XH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "XH_val = XH_val[XH_val['month'] <= holdout_date]\n",
    "\n",
    "yH_val = XH_val['y']\n",
    "XH_val = XH_val.drop(['y'], axis=1)\n",
    "\n",
    "XH_test  = data[data['month'] >= holdout_date]\n",
    "yH_test  = XH_test['y']\n",
    "XH_test  = XH_test.drop(['y'], axis=1)\n",
    "\n",
    "ytr = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "            ).fit(y)\n",
    "y = ytr.fit_transform(y)\n",
    "y = pd.DataFrame(y, columns=['y'])\n",
    "\n",
    "scl_data = scl_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.030214\n",
       "1       0.041713\n",
       "2       0.035841\n",
       "3       0.008930\n",
       "4       0.108869\n",
       "5       0.055046\n",
       "6       0.001346\n",
       "7       0.039021\n",
       "8       0.039388\n",
       "9       0.022141\n",
       "10      0.017615\n",
       "11      0.014190\n",
       "12      0.010275\n",
       "13      0.006606\n",
       "14      0.011743\n",
       "15      0.026667\n",
       "16      0.025688\n",
       "17      0.014679\n",
       "18      0.008073\n",
       "19      0.013700\n",
       "20      0.034251\n",
       "21      0.028991\n",
       "22      0.035352\n",
       "23      0.031927\n",
       "24      0.042202\n",
       "25      0.037309\n",
       "26      0.028379\n",
       "27      0.019205\n",
       "28      0.020795\n",
       "29      0.010398\n",
       "          ...   \n",
       "2152    0.087584\n",
       "2153    0.059205\n",
       "2154    0.050642\n",
       "2155    0.061774\n",
       "2156    0.127217\n",
       "2157    0.108746\n",
       "2158    0.145810\n",
       "2159    0.125994\n",
       "2160    0.171498\n",
       "2161    0.145443\n",
       "2162    0.125505\n",
       "2163    0.115229\n",
       "2164    0.068746\n",
       "2165    0.052477\n",
       "2166    0.059694\n",
       "2167    0.057615\n",
       "2168    0.042569\n",
       "2169    0.075963\n",
       "2170    0.034985\n",
       "2171    0.062263\n",
       "2172    0.040734\n",
       "2173    0.055780\n",
       "2174    0.473884\n",
       "2175    1.000000\n",
       "2176    0.380428\n",
       "2177    0.320000\n",
       "2178    0.508379\n",
       "2179    0.695780\n",
       "2180    0.295291\n",
       "2181    0.283914\n",
       "Name: y, Length: 2182, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016.05\n",
      "(2182, 20)\n",
      "(2182, 20)\n"
     ]
    }
   ],
   "source": [
    "print(scl_data.month.max())\n",
    "print(scl_data.shape)\n",
    "scl_data = scl_data.dropna()\n",
    "print(scl_data.shape)\n",
    "sXH_train = scl_data[scl_data['month'] <= holdout_date-1]\n",
    "syH_train = sXH_train['y']\n",
    "sXH_train = sXH_train.drop(['y'], axis=1)\n",
    "\n",
    "sXH_val = scl_data[scl_data['month'] >= holdout_date-1]\n",
    "sXH_val = sXH_val[sXH_val['month'] <= holdout_date]\n",
    "\n",
    "syH_val = sXH_val['y']\n",
    "sXH_val = sXH_val.drop(['y'], axis=1)\n",
    "\n",
    "\n",
    "sXH_test  = scl_data[scl_data['month'] >= holdout_date]\n",
    "syH_test  = sXH_test['y']\n",
    "sXH_test  = sXH_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2182, 20)\n",
      "(2182, 20)\n",
      "(1393, 19)\n",
      "(1393, 19)\n",
      "(232, 19)\n",
      "(232, 19)\n",
      "'Series' object has no attribute 'columns'\n",
      "(1393, 1)\n",
      "(1393, 1)\n",
      "'Series' object has no attribute 'columns'\n",
      "(232, 1)\n",
      "(232, 1)\n"
     ]
    }
   ],
   "source": [
    "#Build scalers for the scl_data, other --------------------\n",
    "scale_data_splits = [scl_data, sXH_train,sXH_test, syH_train, syH_test]\n",
    "for scl_data in scale_data_splits:\n",
    "    scaler = sklearn.preprocessing.StandardScaler(\n",
    "                ).fit(scl_data)\n",
    "    minmaxer = sklearn.preprocessing.MinMaxScaler([0, 1]\n",
    "                ).fit(scl_data)\n",
    "\n",
    "    scl = scaler.transform(scl_data)\n",
    "    scl = minmaxer.transform(scl_data)\n",
    "    try:\n",
    "        scl_data = pd.DataFrame(scl, columns=scl_data.columns)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "        scl_data = pd.DataFrame(scl, columns=['y'])\n",
    "    print(scl_data.shape)\n",
    "    scl_data = scl_data.dropna()\n",
    "    print(scl_data.shape)\n",
    "    assert np.all(np.isfinite(scl_data))\n",
    "    assert not np.any(np.isnan(scl_data))\n",
    "    \n",
    "    \n",
    "#scl_data[scl_data.columns\n",
    "#   ] = scaler.fit_transform(scl_data[scl_data.columns])\n",
    "\n",
    "#----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's make sure our data came out of the scalers intact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393, 19)\n",
      "(1393,)\n",
      "(232, 19)\n",
      "(232,)\n"
     ]
    }
   ],
   "source": [
    "print(sXH_train.shape)\n",
    "print(syH_train.shape)\n",
    "print(sXH_test.shape)\n",
    "print(syH_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sX = scl_data.drop(['y'], axis=1)\n",
    "sy = scl_data['y']\n",
    "\n",
    "\n",
    "\n",
    "assert np.all(np.isfinite(X))\n",
    "assert np.all(np.isfinite(y))\n",
    "assert not np.any(np.isnan(X))\n",
    "assert not np.any(np.isnan(y))\n",
    "\n",
    "assert np.all(np.isfinite(sX))\n",
    "assert np.all(np.isfinite(sy))\n",
    "assert not np.any(np.isnan(sX))\n",
    "assert not np.any(np.isnan(sy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.144699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.176489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.042825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.080460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.138425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y\n",
       "count  232.000000\n",
       "mean     0.144699\n",
       "std      0.176489\n",
       "min      0.000000\n",
       "25%      0.042825\n",
       "50%      0.080460\n",
       "75%      0.138425\n",
       "max      1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains our a crude RNG, a list of regressors which benefit from scaled data, and hardcoded data used to generate our param_grid, et cetera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2086, 8363, 5711, 9027, 9616, 9636, 8469, 1299, 8386, 1374]\n"
     ]
    }
   ],
   "source": [
    "#Make a short list of random states to insert into randomstate params.\n",
    "scrambler = []\n",
    "for scram in range(0, 10):\n",
    "    scrambler.append(random.randint(0, 10000))   \n",
    "print(scrambler)\n",
    "\n",
    "to_scale = ['SVR']\n",
    "\n",
    "names       = ['AdaBoostRegressor',\n",
    "             'RandomForestRegressor',\n",
    "             'SVR',\n",
    "             #'KNeighborsRegressor',\n",
    "             #'BaggingRegressor',\n",
    "             'GradientBoostingRegressor',\n",
    "             #'LinearRegression',\n",
    "             #'MLPRegressor',\n",
    "             #'SGDRegressor',\n",
    "             'LassoLars'         \n",
    "    \n",
    "]\n",
    "\n",
    "regressors = [AdaBoostRegressor(),\n",
    "              RandomForestRegressor(),\n",
    "              SVR(),\n",
    "              #KNeighborsRegressor(),\n",
    "              #BaggingRegressor(),\n",
    "              GradientBoostingRegressor(),\n",
    "              #LinearRegression(),\n",
    "              #MLPRegressor(),\n",
    "              #SGDRegressor(),\n",
    "              LassoLars()\n",
    "    \n",
    "]\n",
    "\n",
    "param_grids =[ \n",
    "    ['AdaBoostRegressor', dict(\n",
    "        n_estimators=[80, 60, 30],\n",
    "        learning_rate=[1, .5, .01],\n",
    "        loss=['linear', 'square', 'exponential'],\n",
    "        #random_state=scrambler[3:5]\n",
    "        \n",
    "    )],\n",
    "        \n",
    "    ['RandomForestRegressor', dict(\n",
    "        max_depth=[5, 10, 15],\n",
    "        criterion=['mse', 'mae'],\n",
    "        #random_state=scrambler[:2]\n",
    "    )],\n",
    "    ['SVR', dict( #Most params for SVR are turned off right now, too expensive\n",
    "        C=[1, .9],\n",
    "        epsilon=[.1, .05],\n",
    "        #kernel=['poly']\n",
    "    )],\n",
    "    ['GradientBoostingRegressor', dict(\n",
    "        max_depth=[3, 6, 9, 12],\n",
    "        min_samples_split=[2, 4, 8],\n",
    "        presort=[False]\n",
    "    )],\n",
    "    ['LassoLars', dict(\n",
    "        alpha=[0.1, 1, .5, .75],\n",
    "        #random_state=[random.randint(0, 10000)]\n",
    "    )],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search:\n",
    "\n",
    "Here we implement an iterator that executes GridSearchCV and reports the best explained variance. The best_params attribute is then extracted, and used those on the whole training set, then predict on the holdout data.\n",
    "\n",
    "Testing indicates that for some models, the fit on our full dataset modestly outperforms the CV regularly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor:\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done  81 out of  81 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815357721573\n",
      "AdaBoostRegressor R2 with best model, score:\n",
      "0.650823455193\n",
      "RandomForestRegressor:\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  14 out of  18 | elapsed:    3.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done  18 out of  18 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8217710319\n",
      "RandomForestRegressor R2 with best model, score:\n",
      "0.648432896449\n",
      "SVR:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.6s remaining:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.279852405194\n",
      "SVR R2 with best model, score:\n",
      "-0.486678210057\n",
      "GradientBoostingRegressor:\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  36 out of  36 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816597014116\n",
      "GradientBoostingRegressor R2 with best model, score:\n",
      "0.646529772496\n",
      "LassoLars:\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842413278411\n",
      "LassoLars R2 with best model, score:\n",
      "0.861735828473\n",
      "\n",
      "AdaBoostRegressor\n",
      "0.815357721573\n",
      "\n",
      "Best on real:\n",
      "[1950     880.0\n",
      "1951    1126.0\n",
      "1952     935.0\n",
      "1953     285.0\n",
      "1954    2597.0\n",
      "1955    1063.0\n",
      "1956    1122.0\n",
      "1957     480.0\n",
      "1958     656.0\n",
      "1959     636.0\n",
      "1960     406.0\n",
      "1961     374.0\n",
      "1962     248.0\n",
      "1963     398.0\n",
      "1964     678.0\n",
      "1965     667.0\n",
      "1966     431.0\n",
      "1967     381.0\n",
      "1968     475.0\n",
      "1969     836.0\n",
      "1970     738.0\n",
      "1971    1033.0\n",
      "1972     888.0\n",
      "1973    1197.0\n",
      "1974    1052.0\n",
      "1975     842.0\n",
      "1976     859.0\n",
      "1977     520.0\n",
      "1978     378.0\n",
      "1979     455.0\n",
      "         ...  \n",
      "2152     745.0\n",
      "2153     513.0\n",
      "2154     443.0\n",
      "2155     534.0\n",
      "2156    1069.0\n",
      "2157     918.0\n",
      "2158    1221.0\n",
      "2159    1059.0\n",
      "2160    1431.0\n",
      "2161    1218.0\n",
      "2162    1055.0\n",
      "2163     971.0\n",
      "2164     591.0\n",
      "2165     458.0\n",
      "2166     517.0\n",
      "2167     500.0\n",
      "2168     377.0\n",
      "2169     650.0\n",
      "2170     315.0\n",
      "2171     538.0\n",
      "2172     362.0\n",
      "2173     485.0\n",
      "2174    3903.0\n",
      "2175    8204.0\n",
      "2176    3139.0\n",
      "2177    2645.0\n",
      "2178    4185.0\n",
      "2179    5717.0\n",
      "2180    2443.0\n",
      "2181    2350.0\n",
      "Name: y, Length: 232, dtype: float64]\n",
      "\n",
      "RandomForestRegressor\n",
      "0.8217710319\n",
      "\n",
      "Best on real:\n",
      "[1950     880.0\n",
      "1951    1126.0\n",
      "1952     935.0\n",
      "1953     285.0\n",
      "1954    2597.0\n",
      "1955    1063.0\n",
      "1956    1122.0\n",
      "1957     480.0\n",
      "1958     656.0\n",
      "1959     636.0\n",
      "1960     406.0\n",
      "1961     374.0\n",
      "1962     248.0\n",
      "1963     398.0\n",
      "1964     678.0\n",
      "1965     667.0\n",
      "1966     431.0\n",
      "1967     381.0\n",
      "1968     475.0\n",
      "1969     836.0\n",
      "1970     738.0\n",
      "1971    1033.0\n",
      "1972     888.0\n",
      "1973    1197.0\n",
      "1974    1052.0\n",
      "1975     842.0\n",
      "1976     859.0\n",
      "1977     520.0\n",
      "1978     378.0\n",
      "1979     455.0\n",
      "         ...  \n",
      "2152     745.0\n",
      "2153     513.0\n",
      "2154     443.0\n",
      "2155     534.0\n",
      "2156    1069.0\n",
      "2157     918.0\n",
      "2158    1221.0\n",
      "2159    1059.0\n",
      "2160    1431.0\n",
      "2161    1218.0\n",
      "2162    1055.0\n",
      "2163     971.0\n",
      "2164     591.0\n",
      "2165     458.0\n",
      "2166     517.0\n",
      "2167     500.0\n",
      "2168     377.0\n",
      "2169     650.0\n",
      "2170     315.0\n",
      "2171     538.0\n",
      "2172     362.0\n",
      "2173     485.0\n",
      "2174    3903.0\n",
      "2175    8204.0\n",
      "2176    3139.0\n",
      "2177    2645.0\n",
      "2178    4185.0\n",
      "2179    5717.0\n",
      "2180    2443.0\n",
      "2181    2350.0\n",
      "Name: y, Length: 232, dtype: float64]\n",
      "\n",
      "SVR\n",
      "-0.279852405194\n",
      "\n",
      "Best on real:\n",
      "[1950     880.0\n",
      "1951    1126.0\n",
      "1952     935.0\n",
      "1953     285.0\n",
      "1954    2597.0\n",
      "1955    1063.0\n",
      "1956    1122.0\n",
      "1957     480.0\n",
      "1958     656.0\n",
      "1959     636.0\n",
      "1960     406.0\n",
      "1961     374.0\n",
      "1962     248.0\n",
      "1963     398.0\n",
      "1964     678.0\n",
      "1965     667.0\n",
      "1966     431.0\n",
      "1967     381.0\n",
      "1968     475.0\n",
      "1969     836.0\n",
      "1970     738.0\n",
      "1971    1033.0\n",
      "1972     888.0\n",
      "1973    1197.0\n",
      "1974    1052.0\n",
      "1975     842.0\n",
      "1976     859.0\n",
      "1977     520.0\n",
      "1978     378.0\n",
      "1979     455.0\n",
      "         ...  \n",
      "2152     745.0\n",
      "2153     513.0\n",
      "2154     443.0\n",
      "2155     534.0\n",
      "2156    1069.0\n",
      "2157     918.0\n",
      "2158    1221.0\n",
      "2159    1059.0\n",
      "2160    1431.0\n",
      "2161    1218.0\n",
      "2162    1055.0\n",
      "2163     971.0\n",
      "2164     591.0\n",
      "2165     458.0\n",
      "2166     517.0\n",
      "2167     500.0\n",
      "2168     377.0\n",
      "2169     650.0\n",
      "2170     315.0\n",
      "2171     538.0\n",
      "2172     362.0\n",
      "2173     485.0\n",
      "2174    3903.0\n",
      "2175    8204.0\n",
      "2176    3139.0\n",
      "2177    2645.0\n",
      "2178    4185.0\n",
      "2179    5717.0\n",
      "2180    2443.0\n",
      "2181    2350.0\n",
      "Name: y, Length: 232, dtype: float64]\n",
      "\n",
      "GradientBoostingRegressor\n",
      "0.816597014116\n",
      "\n",
      "Best on real:\n",
      "[1950     880.0\n",
      "1951    1126.0\n",
      "1952     935.0\n",
      "1953     285.0\n",
      "1954    2597.0\n",
      "1955    1063.0\n",
      "1956    1122.0\n",
      "1957     480.0\n",
      "1958     656.0\n",
      "1959     636.0\n",
      "1960     406.0\n",
      "1961     374.0\n",
      "1962     248.0\n",
      "1963     398.0\n",
      "1964     678.0\n",
      "1965     667.0\n",
      "1966     431.0\n",
      "1967     381.0\n",
      "1968     475.0\n",
      "1969     836.0\n",
      "1970     738.0\n",
      "1971    1033.0\n",
      "1972     888.0\n",
      "1973    1197.0\n",
      "1974    1052.0\n",
      "1975     842.0\n",
      "1976     859.0\n",
      "1977     520.0\n",
      "1978     378.0\n",
      "1979     455.0\n",
      "         ...  \n",
      "2152     745.0\n",
      "2153     513.0\n",
      "2154     443.0\n",
      "2155     534.0\n",
      "2156    1069.0\n",
      "2157     918.0\n",
      "2158    1221.0\n",
      "2159    1059.0\n",
      "2160    1431.0\n",
      "2161    1218.0\n",
      "2162    1055.0\n",
      "2163     971.0\n",
      "2164     591.0\n",
      "2165     458.0\n",
      "2166     517.0\n",
      "2167     500.0\n",
      "2168     377.0\n",
      "2169     650.0\n",
      "2170     315.0\n",
      "2171     538.0\n",
      "2172     362.0\n",
      "2173     485.0\n",
      "2174    3903.0\n",
      "2175    8204.0\n",
      "2176    3139.0\n",
      "2177    2645.0\n",
      "2178    4185.0\n",
      "2179    5717.0\n",
      "2180    2443.0\n",
      "2181    2350.0\n",
      "Name: y, Length: 232, dtype: float64]\n",
      "\n",
      "LassoLars\n",
      "0.842413278411\n",
      "\n",
      "Best on real:\n",
      "[1950     880.0\n",
      "1951    1126.0\n",
      "1952     935.0\n",
      "1953     285.0\n",
      "1954    2597.0\n",
      "1955    1063.0\n",
      "1956    1122.0\n",
      "1957     480.0\n",
      "1958     656.0\n",
      "1959     636.0\n",
      "1960     406.0\n",
      "1961     374.0\n",
      "1962     248.0\n",
      "1963     398.0\n",
      "1964     678.0\n",
      "1965     667.0\n",
      "1966     431.0\n",
      "1967     381.0\n",
      "1968     475.0\n",
      "1969     836.0\n",
      "1970     738.0\n",
      "1971    1033.0\n",
      "1972     888.0\n",
      "1973    1197.0\n",
      "1974    1052.0\n",
      "1975     842.0\n",
      "1976     859.0\n",
      "1977     520.0\n",
      "1978     378.0\n",
      "1979     455.0\n",
      "         ...  \n",
      "2152     745.0\n",
      "2153     513.0\n",
      "2154     443.0\n",
      "2155     534.0\n",
      "2156    1069.0\n",
      "2157     918.0\n",
      "2158    1221.0\n",
      "2159    1059.0\n",
      "2160    1431.0\n",
      "2161    1218.0\n",
      "2162    1055.0\n",
      "2163     971.0\n",
      "2164     591.0\n",
      "2165     458.0\n",
      "2166     517.0\n",
      "2167     500.0\n",
      "2168     377.0\n",
      "2169     650.0\n",
      "2170     315.0\n",
      "2171     538.0\n",
      "2172     362.0\n",
      "2173     485.0\n",
      "2174    3903.0\n",
      "2175    8204.0\n",
      "2176    3139.0\n",
      "2177    2645.0\n",
      "2178    4185.0\n",
      "2179    5717.0\n",
      "2180    2443.0\n",
      "2181    2350.0\n",
      "Name: y, Length: 232, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "\n",
    "for name, rgsr in zip(names, regressors):\n",
    "    \n",
    "    for item in param_grids:\n",
    "        if item[0]==name:\n",
    "            print(name + ':')\n",
    "            params= item[1]\n",
    "        \n",
    "    \n",
    "    cv = sklearn.model_selection.GridSearchCV(rgsr, param_grid=params,\n",
    "                                              verbose=True, n_jobs=12,\n",
    "                                              cv=3, pre_dispatch=\"2*n_jobs\")\n",
    "    \n",
    "    if name not in to_scale:\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "        fitted = cv.fit(XH_train, yH_train)\n",
    "        score = cv.score(XH_val, yH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(XH_train, yH_train)\n",
    "        bestscore = best.score(XH_test, yH_test)\n",
    "    if name in to_scale:\n",
    "    #TODO: fix\n",
    "        #X_train, y_train, X_test, y_test = sklearn.model_selection.train_test_split(sX, sy)\n",
    "        fitted = cv.fit(sXH_train, syH_train)\n",
    "        score = cv.score(sXH_val, syH_val)\n",
    "        print(score)\n",
    "\n",
    "        best = rgsr.set_params(**cv.best_params_)\n",
    "        bestfit= best.fit(sXH_train, syH_train)\n",
    "        bestscore = best.score(sXH_test, syH_test)\n",
    "\n",
    "    print(name + \" R2 with best model, score:\")\n",
    "    print(bestscore)\n",
    "    \n",
    "    outcomes.append((name, score, cv.cv_results_, cv.best_estimator_, \n",
    "                     cv.best_params_, bestscore, [yH_test, ]))\n",
    "    \n",
    "for nm in range(0, len(outcomes)):\n",
    "    print()\n",
    "    print(outcomes[nm][0])\n",
    "    print(outcomes[nm][1])\n",
    "\n",
    "    print()\n",
    "    print('Best on real:')\n",
    "    print(outcomes[nm][-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis - ANC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            -0.427199\n",
       "Q_GDP                 -0.059282\n",
       "GS_GRANTS_Concentr     0.138242\n",
       "SALEPRICE              0.244251\n",
       "month                  0.269414\n",
       "BIZ_Dist_Concentr      0.305893\n",
       "pct_metro_coverage     0.316672\n",
       "Util_Indx_BBL          0.458529\n",
       "METRO_Concentr         0.766041\n",
       "HOTELS_Concentr        0.766041\n",
       "CLUBS_Concentr         0.766041\n",
       "BANKS_Concentr         0.766041\n",
       "LIQUOR_Concentr        0.766041\n",
       "PHARM_Concentr         0.766041\n",
       "GROC_Concentr          0.766041\n",
       "countIssued            0.809520\n",
       "countBBL_prev_cycle    0.926893\n",
       "countBBL_prev_month    0.963903\n",
       "countBBL               0.972928\n",
       "y                      1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLars\n",
      "LassoLars(alpha=0.1, copy_X=True, eps=2.2204460492503131e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
      "     positive=False, precompute='auto', verbose=False)\n",
      "\n",
      "Score on test data:\n",
      "0.861735828473\n",
      "\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.90816167e+04   1.98453888e+04   1.98531337e+04\n",
      "    1.99704971e+04   1.99704463e+04   1.99014869e+04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.04571657e+01\n",
      "    1.33486371e+02   1.33685727e+02   2.11688346e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   -2.00748155e+02  -2.01109263e+02  -3.38025040e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   8.78805750e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   7.63772122e+02   7.90698297e+02\n",
      "    8.16741450e+02   8.16996685e+02   9.56000736e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.95344818e-01   7.72467293e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#LassoLARS\n",
    "blist = outcomes[-1] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = LassoLars(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.coef_path_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month', -12.270248109846495),\n",
       " ('Unnamed: 0', 0.0),\n",
       " ('Util_Indx_BBL', 0.0),\n",
       " ('SALEPRICE', 0.0),\n",
       " ('Q_GDP', 0.0),\n",
       " ('GS_GRANTS_Concentr', 0.0),\n",
       " ('PHARM_Concentr', 0.0),\n",
       " ('GROC_Concentr', 0.0),\n",
       " ('BANKS_Concentr', 0.0),\n",
       " ('CLUBS_Concentr', 0.0),\n",
       " ('HOTELS_Concentr', 0.0),\n",
       " ('METRO_Concentr', 0.0),\n",
       " ('countBBL_prev_month', 0.0),\n",
       " ('countBBL_prev_cycle', 0.0),\n",
       " ('LIQUOR_Concentr', 0.0033581870019101317),\n",
       " ('countIssued', 0.20059272489304059),\n",
       " ('countBBL', 1.0113707268605232),\n",
       " ('BIZ_Dist_Concentr', 6.4856998937977126),\n",
       " ('pct_metro_coverage', 10.567860821437002)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lars_anc_beta = [i for i in zip(XH_test.columns, prms.coef_)]\n",
    "sorted(lars_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "         n_estimators=60, random_state=None)\n",
      "\n",
      "Score on test data:\n",
      "0.639001698044\n",
      "\n",
      "[  8.10945901e-05   5.05708069e-03   4.23808081e-01   0.00000000e+00\n",
      "   3.26825190e-03   1.99173144e-04   2.69028472e-04   1.23716754e-02\n",
      "   9.28362001e-03   3.05949710e-03   1.37342807e-03   3.89498659e-04\n",
      "   1.27105978e-04   0.00000000e+00   2.43560199e-04   2.25904609e-04\n",
      "   7.80708363e-03   1.78493079e-01   3.53942837e-01]\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "blist = outcomes[0] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = AdaBoostRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countIssued', 0.0),\n",
       " ('CLUBS_Concentr', 0.0),\n",
       " ('Unnamed: 0', 8.1094590078025809e-05),\n",
       " ('BANKS_Concentr', 0.00012710597815412771),\n",
       " ('SALEPRICE', 0.0001991731444612097),\n",
       " ('METRO_Concentr', 0.00022590460949200889),\n",
       " ('HOTELS_Concentr', 0.00024356019866830374),\n",
       " ('Q_GDP', 0.00026902847245823983),\n",
       " ('GROC_Concentr', 0.00038949865877234625),\n",
       " ('PHARM_Concentr', 0.0013734280710337519),\n",
       " ('LIQUOR_Concentr', 0.0030594971041761391),\n",
       " ('month', 0.0032682518996033079),\n",
       " ('Util_Indx_BBL', 0.0050570806899128155),\n",
       " ('pct_metro_coverage', 0.007807083632386011),\n",
       " ('GS_GRANTS_Concentr', 0.0092836200074869323),\n",
       " ('BIZ_Dist_Concentr', 0.01237167537067348),\n",
       " ('countBBL_prev_month', 0.1784930792698384),\n",
       " ('countBBL_prev_cycle', 0.35394283716916208),\n",
       " ('countBBL', 0.42380808113364293)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(ada_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "Score on test data:\n",
      "0.66670081616\n",
      "\n",
      "[  2.71952232e-04   1.51398149e-03   7.25120999e-01   1.20615530e-04\n",
      "   1.52890567e-03   2.25774475e-04   8.80281025e-05   1.47500237e-04\n",
      "   7.73607779e-04   5.32695701e-05   1.86584598e-03   1.77683965e-05\n",
      "   9.26199688e-05   2.09344833e-03   2.34968233e-03   1.67659283e-05\n",
      "   1.45464045e-04   2.27405469e-01   3.61683022e-02]\n"
     ]
    }
   ],
   "source": [
    "#RFR \n",
    "blist = outcomes[1] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = RandomForestRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('METRO_Concentr', 1.6765928325301168e-05),\n",
       " ('GROC_Concentr', 1.776839646357646e-05),\n",
       " ('LIQUOR_Concentr', 5.3269570085663532e-05),\n",
       " ('Q_GDP', 8.8028102527494529e-05),\n",
       " ('BANKS_Concentr', 9.2619968829200095e-05),\n",
       " ('countIssued', 0.00012061552991423581),\n",
       " ('pct_metro_coverage', 0.00014546404507784926),\n",
       " ('BIZ_Dist_Concentr', 0.00014750023748539052),\n",
       " ('SALEPRICE', 0.00022577447457509747),\n",
       " ('Unnamed: 0', 0.00027195223183552311),\n",
       " ('GS_GRANTS_Concentr', 0.00077360777944966166),\n",
       " ('Util_Indx_BBL', 0.0015139814911027363),\n",
       " ('month', 0.0015289056678235867),\n",
       " ('PHARM_Concentr', 0.0018658459754626448),\n",
       " ('CLUBS_Concentr', 0.0020934483342079963),\n",
       " ('HOTELS_Concentr', 0.0023496823259912267),\n",
       " ('countBBL_prev_cycle', 0.036168302239970404),\n",
       " ('countBBL_prev_month', 0.227405468745637),\n",
       " ('countBBL', 0.72512099895523552)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(rfr_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100, presort=False,\n",
      "             random_state=None, subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "Score on test data:\n",
      "0.650453063581\n",
      "\n",
      "[ 0.02526476  0.0445745   0.25613845  0.05661967  0.16149232  0.04215735\n",
      "  0.03799063  0.02799897  0.0239004   0.00576734  0.00496732  0.00623564\n",
      "  0.01148616  0.00696566  0.0060399   0.00346679  0.02553598  0.13438211\n",
      "  0.11901604]\n"
     ]
    }
   ],
   "source": [
    "#GBR  \n",
    "blist = outcomes[3] #this number is how we select which regressor\n",
    "print(blist[0])\n",
    "prms = GradientBoostingRegressor(**blist[4])\n",
    "prms = prms.fit(sXH_train, syH_train)\n",
    "print(prms)\n",
    "print()\n",
    "print('Score on test data:')\n",
    "print(prms.score(XH_test, yH_test))\n",
    "pred  = prms.predict(XH_test)\n",
    "print()\n",
    "print(prms.feature_importances_) #Or whatever other attribute you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('METRO_Concentr', 0.0034667949489451642),\n",
       " ('PHARM_Concentr', 0.0049673192658439089),\n",
       " ('LIQUOR_Concentr', 0.0057673425050446068),\n",
       " ('HOTELS_Concentr', 0.0060399040613221631),\n",
       " ('GROC_Concentr', 0.0062356411758471295),\n",
       " ('CLUBS_Concentr', 0.0069656613262664121),\n",
       " ('BANKS_Concentr', 0.011486159419538695),\n",
       " ('GS_GRANTS_Concentr', 0.023900400086495611),\n",
       " ('Unnamed: 0', 0.025264758903454893),\n",
       " ('pct_metro_coverage', 0.025535982765437698),\n",
       " ('BIZ_Dist_Concentr', 0.027998972698139252),\n",
       " ('Q_GDP', 0.037990634392939551),\n",
       " ('SALEPRICE', 0.042157346797145931),\n",
       " ('Util_Indx_BBL', 0.04457449752261957),\n",
       " ('countIssued', 0.056619668144072009),\n",
       " ('countBBL_prev_cycle', 0.11901603654866419),\n",
       " ('countBBL_prev_month', 0.13438210732230454),\n",
       " ('month', 0.16149231958774748),\n",
       " ('countBBL', 0.25613845252817119)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_anc_beta = [i for i in zip(XH_test.columns, prms.feature_importances_)]\n",
    "sorted(gbr_anc_beta, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adapted from https://pythonspot.com/en/matplotlib-bar-chart/\n",
    "\n",
    "objects     = [j[0] for j in outcomes]\n",
    "y_pos       = np.arange(len(objects))\n",
    "\n",
    "performance = [j[-1] for j in outcomes]\n",
    "for jm in range(len(performance)):\n",
    "    if performance[jm] < 0:\n",
    "        performance[jm] = 0\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('R2 Score')\n",
    "ti = \"Scoring across models for \"+shapef+\", lagging by \"+str(shiftmonths)+ \" months.\"\n",
    "plt.title(ti)\n",
    "fl = './plots/' + shapef + \"_shift\" + str(shiftmonths)\n",
    "plt.savefig(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below is exploratory analysis for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for jm in range(0, 5):\n",
    "    \n",
    "    print(outcomes[jm][0])\n",
    "    \n",
    "    print(outcomes[jm][1])\n",
    "    print(outcomes[jm][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = AdaBoostRegressor(learning_rate=1, loss='square', n_estimators=60)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[0][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = RandomForestRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[1][0])\n",
    "print(bestscore)\n",
    "\n",
    "best = SVR(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[2][0])\n",
    "print(bestscore)\n",
    "\n",
    "\n",
    "best = GradientBoostingRegressor(max_depth=10)\n",
    "bestfit= best.fit(XH_train, yH_train)\n",
    "bestscore = best.score(XH_test, yH_test)\n",
    "print(outcomes[3][0])\n",
    "print(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Xtrain = dat_xtrain.drop(['y'], axis=1)\n",
    "y16 = dat_ytrain['y']\n",
    "X15 = dat15.drop(['y'], axis=1)\n",
    "y15 = dat15['y']\n",
    "\n",
    "fitted    = outcomes[-2][3].fit(X15, y15)\n",
    "predicted = fitted.predict(X16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predicted, columns=['predicted'])\n",
    "dat16 = dat16.reset_index()\n",
    "pred['y'] = dat16['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flagger_ranges(pred):\n",
    "    pred['flag15'] = 0\n",
    "    pred['flag15'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag05'] = 0\n",
    "    pred['flag05'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag10'] = 0\n",
    "    pred['flag10'][pred['predicted'].between(pred['y']*0.85, pred['y']*1.15)\n",
    "                  ] = 1\n",
    "    pred['flag_others']= 0\n",
    "    pred['flag_others'][pred['flag05'] == 0] = 1\n",
    "    return pred\n",
    "pred = flagger_ranges(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
