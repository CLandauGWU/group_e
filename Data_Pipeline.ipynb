{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from downloading_funcs import addr_shape, down_extract_zip\n",
    "from supp_funcs import *\n",
    "import lnks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the BBL list\n",
    "BBL12_17CSV = ['https://opendata.arcgis.com/datasets/82ab09c9541b4eb8ba4b537e131998ce_22.csv', 'https://opendata.arcgis.com/datasets/4c4d6b4defdf4561b737a594b6f2b0dd_23.csv',   'https://opendata.arcgis.com/datasets/d7aa6d3a3fdc42c4b354b9e90da443b7_1.csv',     'https://opendata.arcgis.com/datasets/a8434614d90e416b80fbdfe2cb2901d8_2.csv', 'https://opendata.arcgis.com/datasets/714d5f8b06914b8596b34b181439e702_36.csv',     'https://opendata.arcgis.com/datasets/c4368a66ce65455595a211d530facc54_3.csv',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_pipeline(shapetype, bbl_links, supplement=None,\n",
    "                 dex=None, ts_lst_range=None):\n",
    "    #A pipeline for group_e dataframe operations\n",
    "    \n",
    "    \n",
    "    #Test inputs --------------------------------------------------------------\n",
    "    if supplement:\n",
    "        assert isinstance(supplement, list)\n",
    "    assert isinstance(bbl_links, list)\n",
    "    if ts_lst_range:\n",
    "        assert isinstance(ts_lst_range, list)\n",
    "        assert len(ts_lst_range) == 2 #Must be list of format [start-yr, end-yr]\n",
    "    \n",
    "    #We'll need our addresspoints and our shapefile\n",
    "    if not dex:\n",
    "        dex = addr_shape(shapetype)\n",
    "    \n",
    "    #We need a list of time_unit_of_analysis\n",
    "    if ts_lst_range:\n",
    "        ts_lst = [x+(i/100) for i in range(1,13,1) for x in range(1980, 2025)]\n",
    "        ts_lst = [x for x in ts_lst if \n",
    "                  x >= ts_lst_range[0] and x <= ts_lst_range[1]]\n",
    "        ts_lst = sorted(ts_lst)\n",
    "    if not ts_lst_range:\n",
    "        ts_lst = [x+(i/100) for i in range(1,13,1) for x in range(2012, 2017)]\n",
    "        ts_lst = sorted(ts_lst)\n",
    "    \n",
    "    #Now we need to stack our BBL data ----------------------------------------\n",
    "    \n",
    "    #Begin by forming an empty DF \n",
    "    bbl_df = pd.DataFrame()\n",
    "    for i in bbl_links:\n",
    "        bbl = pd.read_csv(i, encoding='utf-8', low_memory=False)\n",
    "        col_len = len(bbl.columns)\n",
    "        bbl_df = bbl_df.append(bbl)\n",
    "        if len(bbl.columns) != col_len:\n",
    "            print('Column Mismatch!')\n",
    "        del bbl\n",
    "        \n",
    "    bbl_df.LICENSE_START_DATE      = pd.to_datetime(\n",
    "        bbl_df.LICENSE_START_DATE)\n",
    "    \n",
    "    bbl_df.LICENSE_EXPIRATION_DATE = pd.to_datetime(\n",
    "        bbl_df.LICENSE_EXPIRATION_DATE)\n",
    "    \n",
    "    bbl_df.LICENSE_ISSUE_DATE      = pd.to_datetime(\n",
    "        bbl_df.LICENSE_ISSUE_DATE)\n",
    "\n",
    "    \n",
    "    bbl_df.sort_values('LICENSE_START_DATE')\n",
    "        \n",
    "    #Set up our time unit of analysis\n",
    "    bbl_df['month']      = 0\n",
    "    bbl_df['endMonth']   = 0\n",
    "    bbl_df['issueMonth'] = 0\n",
    "    \n",
    "    bbl_df['month'] = bbl_df['LICENSE_START_DATE'].dt.year + (\n",
    "        bbl_df['LICENSE_START_DATE'].dt.month/100\n",
    "    )\n",
    "    bbl_df['endMonth'] = bbl_df['LICENSE_EXPIRATION_DATE'].dt.year + (\n",
    "        bbl_df['LICENSE_EXPIRATION_DATE'].dt.month/100\n",
    "    )\n",
    "    bbl_df['issueMonth'] = bbl_df['LICENSE_ISSUE_DATE'].dt.year + (\n",
    "        bbl_df['LICENSE_ISSUE_DATE'].dt.month/100\n",
    "    )\n",
    "    bbl_df.endMonth.fillna(max(ts_lst))\n",
    "    bbl_df['endMonth'][bbl_df['endMonth'] > max(ts_lst)] = max(ts_lst)\n",
    "       \n",
    "    #Sort on month\n",
    "    bbl_df = bbl_df.dropna(subset=['month'])\n",
    "    bbl_df = bbl_df.set_index(['MARADDRESSREPOSITORYID','month'])\n",
    "    bbl_df = bbl_df.sort_index(ascending=True)\n",
    "    bbl_df.reset_index(inplace=True)\n",
    "    \n",
    "        \n",
    "    bbl_df = bbl_df[bbl_df['MARADDRESSREPOSITORYID'] >= 0]\n",
    "        \n",
    "    bbl_df = bbl_df.dropna(subset=['LICENSESTATUS', 'issueMonth', 'endMonth',\n",
    "                                   'MARADDRESSREPOSITORYID','month', \n",
    "                                   'LONGITUDE', 'LATITUDE'\n",
    "                                  ])\n",
    "    \n",
    "    #Now that we have the BBL data, let's create our flag and points data -----\n",
    "    \n",
    "    #This is the addresspoints, passed from the dex param\n",
    "    addr_df = dex[0]\n",
    "    \n",
    "    #Zip the latlongs\n",
    "    addr_df['geometry'] = [\n",
    "        Point(xy) for xy in zip(\n",
    "            addr_df.LONGITUDE.apply(float), addr_df.LATITUDE.apply(float)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    addr_df['Points']   = addr_df['geometry'] #Duplicate, so raw retains points\n",
    "    \n",
    "    addr_df['dummy_counter'] = 1 #Always one, always dropped before export\n",
    "    \n",
    "    crs='EPSG:4326' #Convenience assignment of crs\n",
    "    \n",
    "    #Now we're stacking for each month ----------------------------------------\n",
    "    \n",
    "    out_gdf = pd.DataFrame() #Empty storage df\n",
    "\n",
    "    for i in ts_lst: #iterate through the list of months\n",
    "                \n",
    "        #dex[1] is the designated shapefile passed from the dex param, \n",
    "        #and should match the shapetype defined in that param\n",
    "        \n",
    "        #Copy of the dex[1] shapefile\n",
    "        shp_gdf = dex[1]\n",
    "        \n",
    "        #Active BBL in month i\n",
    "        bbl_df['inRange'] = 0\n",
    "        bbl_df['inRange'][(bbl_df.endMonth > i) & (bbl_df.month <= i)] = 1\n",
    "        \n",
    "        #Issued BBL in month i\n",
    "        bbl_df['isuFlag'] = 0\n",
    "        bbl_df['isuFlag'][bbl_df.issueMonth == i] = 1\n",
    "        \n",
    "        #Merge BBL and MAR datasets -------------------------------------------\n",
    "        addr    = pd.merge(addr_df, bbl_df, how='left', \n",
    "                        left_on='ADDRESS_ID', right_on='MARADDRESSREPOSITORYID')\n",
    "        addr    = gpd.GeoDataFrame(addr, crs=crs, geometry=addr.geometry)\n",
    "        \n",
    "        \n",
    "        addr.crs = shp_gdf.crs\n",
    "        raw     = gpd.sjoin(shp_gdf, addr, how='left', op='intersects')\n",
    "        \n",
    "        #A simple percent of buildings with active flags per shape,\n",
    "        #and call it a 'utilization index'\n",
    "        numer = raw.groupby('NAME').sum()\n",
    "        numer = numer.inRange\n",
    "        denom = raw.groupby('NAME').sum()\n",
    "        denom = denom.dummy_counter\n",
    "        issue = raw.groupby('NAME').sum()\n",
    "        issue = issue.isuFlag\n",
    "        \n",
    "        flags = []\n",
    "        \n",
    "        utl_inx           = pd.DataFrame(numer/denom)\n",
    "        \n",
    "        utl_inx.columns   = [\n",
    "            'Util_Indx_BBL'\n",
    "        ]\n",
    "        flags.append(utl_inx)\n",
    "        \n",
    "        #This is number of buildings with an active BBL in month i\n",
    "        bbl_count         = pd.DataFrame(numer)\n",
    "        \n",
    "        bbl_count.columns = [\n",
    "            'countBBL'\n",
    "        ]\n",
    "        flags.append(bbl_count)\n",
    "        \n",
    "        #This is number of buildings that were issued a BBL in month i\n",
    "        isu_count         = pd.DataFrame(issue)\n",
    "        isu_count.columns = [\n",
    "            'countIssued'\n",
    "        ]\n",
    "        flags.append(isu_count)\n",
    "        \n",
    "        for flag in flags:\n",
    "            flag.crs = shp_gdf.crs\n",
    "\n",
    "            shp_gdf = shp_gdf.merge(flag,\n",
    "                                    how=\"left\", left_on='NAME', right_index=True)\n",
    "        shp_gdf['month'] = i\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Head will be the list of retained columns\n",
    "        head = ['NAME', 'Util_Indx_BBL',\n",
    "               'countBBL', 'countIssued',\n",
    "               'month', 'geometry']\n",
    "        shp_gdf = shp_gdf[head]\n",
    "        \n",
    "        \n",
    "        if supplement: #this is where your code will be fed into the pipeline.\n",
    "            \n",
    "            #To include time unit of analysis, pass 'i=i' as the last\n",
    "            #item in your args list over on lnks.py, and the for-loop\n",
    "            #will catch that. Else, it will pass your last item as an arg.\n",
    "            \n",
    "            #Ping CDL if you need to pass a func with more args and we\n",
    "            #can extend this.\n",
    "            \n",
    "            for supp_func in supplement:\n",
    "                if len(supp_func) == 2:\n",
    "                    shp_gdf = supp_func[0](shp_gdf, raw, supp_func[1])\n",
    "                if len(supp_func) == 3:\n",
    "                    if supp_func[2] == 'i=i':\n",
    "                        shp_gdf = supp_func[0](shp_gdf, raw, supp_func[1], i=i)\n",
    "                    if supp_func[2] != 'i=i':\n",
    "                        shp_gdf = supp_func[0](shp_gdf, raw, supp_func[1],\n",
    "                                              supp_func[2])\n",
    "                if len(supp_func) == 4:\n",
    "                    if supp_func[3] == 'i=i':\n",
    "                        shp_gdf = supp_func[0](shp_gdf, raw, supp_func[1],\n",
    "                                              supp_func[2], i=i)\n",
    "                    if supp_func[3] != 'i=i':\n",
    "                        shp_gdf = supp_func[0](shp_gdf, raw, supp_func[1],\n",
    "                                              supp_func[2], supp_func[3])\n",
    "        \n",
    "        out_gdf = out_gdf.append(shp_gdf) #This does the stacking\n",
    "        print('Merged month:', i)\n",
    "        del shp_gdf, addr, utl_inx #Save me some memory please!\n",
    "    \n",
    "    #Can't have strings in our matrix\n",
    "    out_gdf = pd.get_dummies(out_gdf, columns=['NAME'])\n",
    "    out_gdf = out_gdf.drop('geometry', axis=1)\n",
    "    \n",
    "    out_gdf.to_csv('./data/' + shapetype + '_out.csv') #Save\n",
    "    \n",
    "    return [bbl_df, addr_df, out_gdf, raw] #Remove this later, for testing now\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dex = addr_shape('anc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = data_pipeline('anc', BBL12_17CSV, supplement=lnks.supplm, dex=dex, ts_lst_range=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets[2].T #Our number of rows equals our number of shapes * number of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
